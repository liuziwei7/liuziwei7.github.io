<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Ziwei Liu; 刘子纬; Computer Vision; Deep Learning; Computer Graphics; Multimedia Lab; MMLAB; The Chinese University of Hong Kong; CUHK; UC Berkeley; ICSI; Nanyang Technological University; NTU">
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.min.js"></script>
<link rel="author" href="https://liuziwei7.github.io/">

    <title>Ziwei Liu - Publications</title>
    <style>

@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : rgb(224, 224, 224); }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
.container_title { width : 750px; margin : 20px auto; border-radius: 10px;  padding : 20px;  clear:both;}
.iframe_video {float: left; margin-right: 30px}
#bio {
    padding-top : 20px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; margin-right : 100px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>

    <div class="container">
        <h2>
            <a href="./index.html">Home</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="./research.html">Research</a>&nbsp;&nbsp;&middot;&nbsp;
            <a href="./publications.html">Publications</a>&nbsp;&nbsp;&middot;&nbsp;
            <a href="./softwares.html">Softwares</a>&nbsp;&nbsp;&middot;&nbsp;
            <a href="./team.html">Team</a>&nbsp;&nbsp;&middot;&nbsp;
            <a href="./services.html">Services</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="./awards.html">Awards</a>
        </h2>
    </div>

	<div class="container">
	<h2>Publications <small><a href="https://scholar.google.com/citations?user=lc45xlcAAAAJ">[Google Scholar]</a></small> </h2>
        <br>
        <h3>2023</h3>
        <div class="publication">
            <img src="./homepage_files/freeu_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://chenyangsi.top/FreeU/">FreeU: Free Lunch in Diffusion U-Net</a>
                </strong>
                <br>
                <br>
                Chenyang Si, Ziqi Huang, Yuming Jiang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.11497">PDF</a>
                    <a href="https://chenyangsi.top/FreeU/">Project Page</a>
                    <a href="https://github.com/ChenyangSi/FreeU">Code</a>
                    <a href="https://www.youtube.com/watch?v=-CZ5uWxvX30">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/lavie_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://vchitect.github.io/LaVie-project/">LaVie: High-Quality Video Generation with Cascaded Latent Diffusion Models</a>
                </strong>
                <br>
                <br>
                Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, Yuwei Guo, Tianxing Wu, Chenyang Si, Yuming Jiang, Cunjian Chen, Chen Change Loy, Bo Dai, Dahua Lin, Yu Qiao, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.15103">PDF</a>
                    <a href="https://vchitect.github.io/LaVie-project/">Project Page</a>
                    <a href="https://github.com/Vchitect/LaVie">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/difftf_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://ziangcao0312.github.io/difftf_pages/">Large-Vocabulary 3D Diffusion Model with Transformer</a>
                </strong>
                <br>
                <br>
                Ziang Cao, Fangzhou Hong, Tong Wu, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.07920">PDF</a>
                    <a href="https://ziangcao0312.github.io/difftf_pages/">Project Page</a>
                    <a href="https://github.com/ziangcao0312/DiffTF">Code</a>
                    <a href="https://www.youtube.com/watch?v=8KIZg-cWBeY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dreamgaussian_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://dreamgaussian.github.io/">DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation</a>
                </strong>
                <br>
                <br>
                Jiaxiang Tang, Jiawei Ren, Hang Zhou, <b>Ziwei Liu</b>, Gang Zeng.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.16653">PDF</a>
                    <a href="https://dreamgaussian.github.io/">Project Page</a>
                    <a href="https://github.com/dreamgaussian/dreamgaussian">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/citydreamer_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://haozhexie.com/project/city-dreamer">CityDreamer: Compositional Generative Model of Unbounded 3D Cities</a>
                </strong>
                <br>
                <br>
                Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.00610">PDF</a>
                    <a href="https://haozhexie.com/project/city-dreamer">Project Page</a>
                    <a href="https://github.com/hzxie/city-dreamer">Code</a>
                    <a href="https://www.youtube.com/watch?v=te4zinLTYz0">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seganypoint_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2305.14207">Segment Any Point Cloud Sequences by Distilling Vision Foundation Models</a>
                </strong>
                <br>
                <br>
                Youquan Liu, Lingdong Kong, Jun Cen, Runnan Chen, Wenwei Zhang, Liang Pan, Kai Chen, <b>Ziwei Liu</b>.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2023 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.09347">PDF</a>
                    <a href="https://github.com/youquanl/Segment-Any-Point-Cloud">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/incontext_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2301.13670">What Makes Good Examples for Visual In-Context Learning?</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Kaiyang Zhou, <b>Ziwei Liu</b>.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2301.13670">PDF</a>
                    <a href="https://github.com/ZhangYuanhan-AI/visual_prompt_retrieval">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/renderme_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://renderme-360.github.io/">RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars</a>
                </strong>
                <br>
                <br>
                Dongwei Pan, Long Zhuo, Jingtan Piao, Huiwen Luo, Wei Cheng, Yuxin Wang, Siming Fan, Shengqi Liu, Lei Yang, Bo Dai, <b>Ziwei Liu</b>, Chen Change Loy, Chen Qian, Wayne Wu, Dahua Lin, Kwan-Yee Lin.
                <br>
                <em>NeurIPS (Datasets and Benchmarks Track), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.13353">PDF</a>
                    <a href="https://renderme-360.github.io/">Project Page</a>
                    <a href="https://github.com/RenderMe-360/RenderMe-360">Code</a>
                    <a href="https://openxdlab.org.cn/details/RenFace">Press</a>
                    <a href="https://www.youtube.com/watch?v=L4YTBVg68vM">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/rerender_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/rerender/">Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Yifan Zhou, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>SIGGRAPH Asia (Conference Track), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.05425">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/rerender/">Project Page</a>
                    <a href="https://github.com/williamyang1991/Rerender_A_Video">Code</a>
                    <a href="https://huggingface.co/spaces/Anonymous-sub/Rerender">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/text2performer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://yumingj.github.io/projects/Text2Performer.html">Text2Performer: Text-Driven Human Video Generation</a>
                </strong>
                <br>
                <br>
                Yuming Jiang, Shuai Yang, Tong Liang Koh, Wayne Wu, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.08483">PDF</a>
                    <a href="https://yumingj.github.io/projects/Text2Performer.html">Project Page</a>
                    <a href="https://github.com/yumingj/Text2Performer">Code</a>
                    <a href="https://www.youtube.com/watch?v=YwhaJUk_qo0">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/sherf_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://skhu101.github.io/SHERF/">SHERF: Generalizable Human NeRF from a Single Image</a>
                </strong>
                <br>
                <br>
                Shoukang Hu, Fangzhou Hong, Liang Pan, Haiyi Mei, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.12791">PDF</a>
                    <a href="https://skhu101.github.io/SHERF/">Project Page</a>
                    <a href="https://github.com/skhu101/SHERF">Code</a>
                    <a href="https://www.youtube.com/watch?v=xyiv-cW6VcI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/remodiffuse_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html">ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model</a>
                </strong>
                <br>
                <br>
                Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong, Huirong Li, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.01116">PDF</a>
                    <a href="https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html">Project Page</a>
                    <a href="https://github.com/mingyuan-zhang/ReMoDiffuse">Code</a>
                    <a href="https://www.youtube.com/watch?v=wSddrIA_2p8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/sparsenerf_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://sparsenerf.github.io/">SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis</a>
                </strong>
                <br>
                <br>
                Guangcong Wang, Zhaoxi Chen, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.16196">PDF</a>
                    <a href="https://sparsenerf.github.io/">Project Page</a>
                    <a href="https://github.com/Wanggcong/SparseNeRF">Code</a>
                    <a href="https://www.youtube.com/watch?v=V0yCTakA964">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/robo3d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ldkong.com/Robo3D">Robo3D: Towards Robust and Reliable 3D Perception against Corruptions</a>
                </strong>
                <br>
                <br>
                Lingdong Kong, Youquan Liu, Xin Li, Runnan Chen, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <em><font color="red" size="2">(ICLR 2023 SR4AD Best Paper Award)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.17597">PDF</a>
                    <a href="https://ldkong.com/Robo3D">Project Page</a>
                    <a href="https://github.com/ldkong1205/Robo3D">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/rangeformer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ldkong.com/RangeFormer">Rethinking Range View Representation for LiDAR Segmentation</a>
                </strong>
                <br>
                <br>
                Lingdong Kong, Youquan Liu, Runnan Chen, Yuexin Ma, Xinge Zhu, Yikang Li, Yuenan Hou, Yu Qiao, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.05367">PDF</a>
                    <a href="https://ldkong.com/RangeFormer">Project Page</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unitedhuman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://unitedhuman.github.io/">UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation</a>
                </strong>
                <br>
                <br>
                Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Wayne Wu, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.05367">PDF</a>
                    <a href="https://unitedhuman.github.io/">Project Page</a>
                    <a href="https://github.com/UnitedHuman/UnitedHuman">Code</a>
                    <a href="https://www.youtube.com/watch?v=pdsfUYFDLSw">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/synbody_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://synbody.github.io/">SynBody: Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling</a>
                </strong>
                <br>
                <br>
                Zhitao Yang, Zhongang Cai, Haiyi Mei, Shuai Liu, Zhaoxi Chen, Weiye Xiao, Yukun Wei, Zhongfei Qing, Chen Wei, Bo Dai, Wayne Wu, Chen Qian, Dahua Lin, <b>Ziwei Liu</b>, Lei Yang.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.17368">PDF</a>
                    <a href="https://synbody.github.io/">Project Page</a>
                    <a href="https://github.com/SynBody/SynBody">Code</a>
                    <a href="https://openxdlab.org.cn/details/SynBody">Press</a>
                    <a href="https://www.youtube.com/watch?v=ogXpRB9zR9A">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/renbody_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://dna-rendering.github.io/">DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering</a>
                </strong>
                <br>
                <br>
                Wei Cheng, Ruixiang Chen, Wanqi Yin, Siming Fan, Keyu Chen, Honglin He, Huiwen Luo, Zhongang Cai, Jingbo Wang, Yang Gao, Zhengming Yu, Zhengyu Lin, Daxuan Ren, Lei Yang, <b>Ziwei Liu</b>, Chen Change Loy, Chen Qian, Wayne Wu, Dahua Lin, Bo Dai, Kwan-Yee Lin.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.10173">PDF</a>
                    <a href="https://dna-rendering.github.io/">Project Page</a>
                    <a href="https://github.com/DNA-Rendering/DNA-Rendering">Code</a>
                    <a href="https://openxdlab.org.cn/details/RenBody">Press</a>
                    <a href="https://www.youtube.com/watch?v=C5mtexVS3DU">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/styleganex_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/styleganex/">StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Liming Jiang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.06146">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/styleganex/">Project Page</a>
                    <a href="https://github.com/williamyang1991/StyleGANEX">Code</a>
                    <a href="https://www.youtube.com/watch?v=8oK0TXQmxg8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deformtoon3d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/deformtoon3d/">DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields</a>
                </strong>
                <br>
                <br>
                Junzhe Zhang, Yushi Lan, Shuai Yang, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.04410">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/deformtoon3d/">Project Page</a>
                    <a href="https://github.com/junzhezhang/DeformToon3D">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/animeinbet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2309.16643">Deep Geometrized Cartoon Line Inbetweening</a>
                </strong>
                <br>
                <br>
                Siyao Li, Tianpei Gu, Weiye Xiao, Henghui Ding, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.16643">PDF</a>
                    <a href="https://github.com/lisiyao21/AnimeInbet">Code</a>
                    <a href="https://www.youtube.com/watch?v=iUF-LsqFKpI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/cloth2body_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2309.16189">Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing</a>
                </strong>
                <br>
                <br>
                Lu Dai, Liqian Ma, Shenhan Qian, Hao Liu, <b>Ziwei Liu</b>, Hui Xiong.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.16189">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/omniobject3d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://omniobject3d.github.io/">OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation</a>
                </strong>
                <br>
                <br>
                Tong Wu, Jiarui Zhang, Xiao Fu, Yuxin Wang, Jiawei Ren, Liang Pan, Wayne Wu, Lei Yang, Jiaqi Wang, Chen Qian, Dahua Lin, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <em><font color="red" size="2">(Best Paper Award Candidate, 12 out of 9155)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2301.07525">PDF</a>
                    <a href="https://omniobject3d.github.io/">Project Page</a>
                    <a href="https://github.com/omniobject3d/OmniObject3D/tree/main">Code</a>
                    <a href="https://www.youtube.com/watch?v=UIGI5OjSZqc">Demo</a>
                    <a href="https://openxdlab.org.cn/details/OmniObject3D">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/lasermix_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ldkong.com/LaserMix">LaserMix for Semi-Supervised LiDAR Semantic Segmentation</a>
                </strong>
                <br>
                <br>
                Lingdong Kong, Jiawei Ren, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023 <font color="#e86e14">(Highlight)</font> </em>
                <br>
                <em><font color="red" size="2">(PREMIA Best Student Paper Award)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.00026">PDF</a>
                    <a href="https://ldkong.com/LaserMix">Project Page</a>
                    <a href="https://github.com/ldkong1205/LaserMix">Code</a>
                    <a href="https://www.youtube.com/watch?v=Xkwa5-dT0g4">Demo</a>
                    <a href="https://zhuanlan.zhihu.com/p/528689803">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/f2nerf_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://totoro97.github.io/projects/f2-nerf/">F2-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories</a>
                </strong>
                <br>
                <br>
                Peng Wang, Yuan Liu, Zhaoxi Chen, Lingjie Liu, <b>Ziwei Liu</b>, Taku Komura, Christian Theobalt, Wenping Wang.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023 <font color="#e86e14">(Highlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.15951">PDF</a>
                    <a href="https://totoro97.github.io/projects/f2-nerf/">Project Page</a>
                    <a href="https://github.com/totoro97/f2-nerf">Code</a>
                    <a href="https://www.marktechpost.com/2023/04/04/this-ai-paper-introduces-f2nerf-a-new-grid-based-nerf-system-for-fast-and-efficient-novel-view-synthesis/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pvsg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Panoptic_Video_Scene_Graph_Generation_CVPR_2023_paper.pdf">Panoptic Video Scene Graph Generation</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Wenxuan Peng, Xiangtai Li, Zujin Guo, Liangyu Chen, Bo Li, Zheng Ma, Wayne Zhang, Kaiyang Zhou, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Panoptic_Video_Scene_Graph_Generation_CVPR_2023_paper.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dgm_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">Detecting and Grounding Multi-Modal Media Manipulation</a>
                </strong>
                <br>
                <br>
                Rui Shao, Tianxing Wu, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.02556">PDF</a>
                    <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">Project Page</a>
                    <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">Code</a>
                    <a href="https://www.youtube.com/watch?v=EortO0cqnGE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/coldiffusion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ziqihuangg.github.io/projects/collaborative-diffusion.html">Collaborative Diffusion for Multi-Modal Face Generation and Editing</a>
                </strong>
                <br>
                <br>
                Ziqi Huang, Kelvin C.K. Chan, Yuming Jiang, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.10530">PDF</a>
                    <a href="https://ziqihuangg.github.io/projects/collaborative-diffusion.html">Project Page</a>
                    <a href="https://github.com/ziqihuangg/Collaborative-Diffusion">Code</a>
                    <a href="https://www.youtube.com/watch?v=inLK4c8sNhc">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/diffgesture_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2303.09119">Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation</a>
                </strong>
                <br>
                <br>
                Lingting Zhu, Xian Liu, Xuanyu Liu, Rui Qian, <b>Ziwei Liu</b>, Lequan Yu.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.09119">PDF</a>
                    <a href="https://github.com/Advocate99/DiffGesture">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/stylesync_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/StyleSync">StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator</a>
                </strong>
                <br>
                <br>
                Jiazhi Guan, Zhanwang Zhang, Hang Zhou, Tianshu Hu, Kaisiyuan Wang, Dongliang He, Haocheng Feng, Jingtuo Liu, Errui Ding, <b>Ziwei Liu</b>, Jingdong Wang.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.05445">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/StyleSync">Project Page</a>
                    <a href="https://github.com/guanjz20/StyleSync">Code</a>
                    <a href="https://www.youtube.com/watch?v=yAPDl2dVonY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/sfmoe_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2206.04046">Sparse Mixture-of-Experts are Domain Generalizable Learners</a>
                </strong>
                <br>
                <br>
                Bo Li, Yifei Shen, Jingkang Yang, Yezhen Wang, Jiawei Ren, Tong Che, Jun Zhang, <b>Ziwei Liu</b>.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2023 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2206.04046">PDF</a>
                    <a href="https://github.com/Luodian/SF-MoE-DG">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/eva3d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hongfz16.github.io/projects/EVA3D.html">EVA3D: Compositional 3D Human Generation from 2D Image Collections</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong, Zhaoxi Chen, Yushi Lan, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2023 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2210.04888">PDF</a>
                    <a href="https://hongfz16.github.io/projects/EVA3D.html">Project Page</a>
                    <a href="https://github.com/hongfz16/EVA3D">Code</a>
                    <a href="https://www.youtube.com/watch?v=JNV0FJ0aDWM">Demo</a>
                    <a href="https://www.unite.ai/creating-full-body-deepfakes-by-combining-multiple-nerfs/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/voxurf_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2208.12697">Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction</a>
                </strong>
                <br>
                <br>
                Tong Wu, Jiaqi Wang, Xingang Pan, Xudong Xu, Christian Theobalt, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2023 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.12697">PDF</a>
                    <a href="https://github.com/wutong16/Voxurf">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/diffmimic_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://diffmimic.github.io/">DiffMimic: Efficient Motion Mimicking with Differentiable Physics</a>
                </strong>
                <br>
                <br>
                Jiawei Ren*, Cunjun Yu*, Siwei Chen, Xiao Ma, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2023 </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.03274">PDF</a>
                    <a href="https://diffmimic.github.io/">Project Page</a>
                    <a href="https://github.com/jiawei-ren/diffmimic">Code</a>
                    <a href="https://diffmimic-demo-main-g7h0i8.streamlit.app/">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mfm_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/mfm/">Masked Frequency Modeling for Self-Supervised Visual Pre-Training</a>
                </strong>
                <br>
                <br>
                Jiahao Xie, Wei Li, Xiaohang Zhan, <b>Ziwei Liu</b>, Yew Soon Ong, Chen Change Loy.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2023 </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2206.07706">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/mfm/">Project Page</a>
                    <a href="https://github.com/Jiahao000/MFM">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/bibench_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2301.11233">BiBench: Benchmarking and Analyzing Network Binarization</a>
                </strong>
                <br>
                <br>
                Haotong Qin, Mingyuan Zhang, Yifu Ding, Aoyu Li, Zhongang Cai, <b>Ziwei Liu</b>, Fisher Yu, Xianglong Liu.
                <br>
                <em>International Conference on Machine Learning (ICML), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2301.11233">PDF</a>
                    <a href="https://htqin.github.io/Projects/BiBench/">Project Page</a>
                    <a href="https://github.com/htqin/BiBench">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/gridreenactment_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://s2023.siggraph.org/presentation/?id=papers_384&sess=sess132">Efficient Video Portrait Reenactment via Grid-based Codebook</a>
                </strong>
                <br>
                <br>
                Kaisiyuan Wang, Hang Zhou, Qianyi Wu, Jiaxiang Tang, Zhiliang Xu, Borong Liang, Tianshu Hu, Errui Ding, Jingtuo Liu, <b>Ziwei Liu</b>, Jingdong Wang.
                <br>
                <em>SIGGRAPH (Conference Track), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://s2023.siggraph.org/presentation/?id=papers_384&sess=sess132">PDF</a>
                    <a href="https://github.com/uniBruce/VPGC">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/vqreenact_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25354">Robust Video Portrait Reenactment via Personalized Representation Quantization</a>
                </strong>
                <br>
                <br>
                Kaisiyuan Wang, Changcheng Liang, Hang Zhou, Jiaxiang Tang, Qianyi Wu, Dongliang He, Zhibin Hong, Jingtuo Liu, Errui Ding, <b>Ziwei Liu</b>, Jingdong Wang.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25354">PDF</a>
                    <a href="https://github.com/uniBruce/VPNQ">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seco_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2203.13535">SeCo: Separating Unknown Musical Visual Sounds with Consistency Guidance</a>
                </strong>
                <br>
                <br>
                Xinchi Zhou, Dongzhan Zhou, Wanli Ouyang, Hang Zhou, <b>Ziwei Liu</b>, Di Hu.
                <br>
                <em>Winter Conf. on Applications of Computer Vision (WACV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.13535">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/makeavolume_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2307.10094">Make-A-Volume: Leveraging Latent Diffusion Models for Cross-Modality 3D Brain MRI Synthesis</a>
                </strong>
                <br>
                <br>
                Lingting Zhu, Zeyue Xue, Zhenchao Jin, Xian Liu, Jingzhen He, <b>Ziwei Liu</b>, Lequan Yu.
                <br>
                <em>Medical Image Comp. and Computer Assisted Interv. (MICCAI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.10094">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/3dsketch_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/SSSP">Make Your Brief Stroke Real and Stereoscopic: 3D-Aware Simplified Sketch to Portrait Generation</a>
                </strong>
                <br>
                <br>
                Yasheng Sun, Qianyi Wu, Hang Zhou, Kaisiyuan Wang, Tianshu Hu, Chen-Chieh Liao, Dongliang He, Jingtuo Liu, Errui Ding, Jingdong Wang, Shio Miyafuji, <b>Ziwei Liu</b>, Hideki Koike.
                <br>
                <em>International Conference on Multimodal Interaction (ICMI), 2023 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.06857">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/SSSP">Project Page</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seqdeepfake_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">Robust Sequential DeepFake Detection</a>
                </strong>
                <br>
                <br>
                Rui Shao, Tianxing Wu, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.14991">PDF</a>
                    <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">Project Page</a>
                    <a href="https://github.com/rshaojimmy/SeqDeepFake">Code</a>
                    <a href="https://lifehkbueduhk-my.sharepoint.com/:f:/g/personal/16483782_life_hkbu_edu_hk/Evp-uhtWYMBLi9G9JlPcKCEBewkMqPCU69L4Kf29qDQaOw?e=G9JaRm">Dataset</a>
                    <a href="https://news.cgtn.com/news/2022-09-13/-Tech-Please-Are-deepfakes-harming-your-cybersecurity--1diuS6uGXIs/index.html">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dgm_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">Detecting and Grounding Multi-Modal Media Manipulation</a>
                </strong>
                <br>
                <br>
                Rui Shao, Tianxing Wu, Jianlong Wu, Liqiang Nie, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.14203">PDF</a>
                    <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">Project Page</a>
                    <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">Code</a>
                    <a href="https://www.youtube.com/watch?v=EortO0cqnGE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mosaicfusion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2309.13042">MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation</a>
                </strong>
                <br>
                <br>
                Jiahao Xie, Wei Li, Xiangtai Li, <b>Ziwei Liu</b>, Yew Soon Ong, Chen Change Loy.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.13042">PDF</a>
                    <a href="https://github.com/Jiahao000/MosaicFusion">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/relitalk_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="http://haonanqiu.com/projects/ReliTalk.html">ReliTalk: Relightable Talking Portrait Generation from a Single Video</a>
                </strong>
                <br>
                <br>
                Haonan Qiu, Zhaoxi Chen, Yuming Jiang, Hang Zhou, Xiangyu Fan, Lei Yang, Wayne Wu, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2309.02434">PDF</a>
                    <a href="http://haonanqiu.com/projects/ReliTalk.html">Project Page</a>
                    <a href="https://github.com/arthur-qiu/ReliTalk">Code</a>
                    <a href="https://www.youtube.com/watch?v=tS2Tek_72J0">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pointhps_logo.png" class="publogo" width="200 px">
            <p>
                <strong>
                    <a href="https://caizhongang.github.io/projects/PointHPS/">PointHPS: Cascaded 3D Human Pose and Shape Estimation from Point Clouds</a>
                </strong>
                <br>
                <br>
                Zhongang Cai*, Liang Pan*, Chen Wei, Wanqi Yin, Fangzhou Hong, Mingyuan Zhang, Chen Change Loy, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.14492">PDF</a>
                    <a href="https://caizhongang.github.io/projects/PointHPS/">Project Page</a>
                    <a href="https://github.com/caizhongang/PointHPS">Code</a>
                    <a href="https://www.youtube.com/watch?v=6RpbGBOBItU">Video</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/humanliff_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://skhu101.github.io/HumanLiff/">HumanLiff: Layer-wise 3D Human Generation with Diffusion Model</a>
                </strong>
                <br>
                <br>
                Shoukang Hu, Fangzhou Hong, Tao Hu, Liang Pan, Haiyi Mei, Weiye Xiao, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.09712">PDF</a>
                    <a href="https://skhu101.github.io/HumanLiff/">Project Page</a>
                    <a href="https://github.com/skhu101/HumanLiff">Code</a>
                    <a href="https://www.youtube.com/watch?v=WbZhELYfnp8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/linkcontext_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2308.07891">Link-Context Learning for Multimodal LLMs</a>
                </strong>
                <br>
                <br>
                Yan Tai, Weichen Fan, Zhao Zhang, Feng Zhu, Rui Zhao, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.07891">PDF</a>
                    <a href="https://github.com/isekai-portal/Link-Context-Learning">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/hierarchyflow_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2308.06909">Hierarchy Flow For High-Fidelity Image-to-Image Translation</a>
                </strong>
                <br>
                <br>
                Weichen Fan, Jinghuan Chen, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.06909">PDF</a>
                    <a href="https://github.com/WeichenFan/HierarchyFlow">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/tada_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://tadaconv-iclr2022.github.io/">Temporally-Adaptive Models for Efficient Video Understanding</a>
                </strong>
                <br>
                <br>
                Ziyuan Huang, Shiwei Zhang, Liang Pan, Zhiwu Qing, Mingqian Tang, <b>Ziwei Liu</b>, Marcelo H. Ang Jr.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.05787">PDF</a>
                    <a href="https://tadaconv-iclr2022.github.io/">Project Page</a>
                    <a href="https://github.com/alibaba-mmai-research/TAdaConv">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/genbench_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2307.13697">Benchmarking and Analyzing Generative Data for Visual Recognition</a>
                </strong>
                <br>
                <br>
                Bo Li, Haotian Liu, Liangyu Chen, Yong Jae Lee, Chunyuan Li, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.13697">PDF</a>
                    <a href="https://github.com/Luodian/GenBench">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pairnet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2307.08699">Pair then Relation: Pair-Net for Panoptic Scene Graph Generation</a>
                </strong>
                <br>
                <br>
                Jinghao Wang,  Zhengyu Wen,  Xiangtai Li,  Jingkang Yang,  Zujing Guo, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.08699">PDF</a>
                    <a href="https://github.com/king159/Pair-Net">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/funqa_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://funqa-benchmark.github.io/">FunQA: Towards Surprising Video Comprehension</a>
                </strong>
                <br>
                <br>
                Binzhu Xie, Sicheng Zhang, Zitang Zhou, Bo Li, Yuanhan Zhang, Jack Hessel, Jingkang Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.14899">PDF</a>
                    <a href="https://funqa-benchmark.github.io/">Project Page</a>
                    <a href="https://github.com/Jingkang50/FunQA">Code</a>
                    <a href="https://www.youtube.com/watch?v=Uh6A4h-Nm78">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mimicit_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://otter-ntu.github.io/">MIMIC-IT: Multi-Modal In-Context Instruction Tuning</a>
                </strong>
                <br>
                <br>
                Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Fanyi Pu, Jingkang Yang, Chunyuan Li, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.05425">PDF</a>
                    <a href="https://otter-ntu.github.io/">Project Page</a>
                    <a href="https://github.com/Luodian/Otter">Code</a>
                    <a href="https://www.youtube.com/watch?v=K8o_LKGQJhs">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/ottermodel_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://otter-ntu.github.io/">Otter: A Multi-Modal Model with In-Context Instruction Tuning</a>
                </strong>
                <br>
                <br>
                Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.03726">PDF</a>
                    <a href="https://otter-ntu.github.io/">Project Page</a>
                    <a href="https://github.com/Luodian/Otter">Code</a>
                    <a href="https://www.youtube.com/watch?v=r-YM4DGGAdE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mmbench_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://opencompass.org.cn/MMBench">MMBench: Is Your Multi-modal Model an All-around Player?</a>
                </strong>
                <br>
                <br>
                Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, <b>Ziwei Liu</b>, Kai Chen, Dahua Lin.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.06281">PDF</a>
                    <a href="https://opencompass.org.cn/MMBench">Project Page</a>
                    <a href="https://github.com/open-compass/MMBench">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/internvid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2307.06942">InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation</a>
                </strong>
                <br>
                <br>
                Yi Wang, Yinan He, Yizhuo Li, Kunchang Li, Jiashuo Yu, Xin Ma, Xinyuan Chen, Yaohui Wang, Ping Luo, <b>Ziwei Liu</b>, Yali Wang, Limin Wang, Yu Qiao.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2307.06942">PDF</a>
                    <a href="https://github.com/OpenGVLab/InternVideo/tree/main/Data/InternVid">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seganyrgbd_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2305.14207">SAD: Segment Any RGBD</a>
                </strong>
                <br>
                <br>
                Jun Cen, Yizheng Wu, Kewei Wang, Xingyi Li, Jingkang Yang, Yixuan Pei, Lingdong Kong, <b>Ziwei Liu</b>, Qifeng Chen.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.14207">PDF</a>
                    <a href="https://github.com/Jun-CEN/SegmentAnyRGBD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deepfakeadapter_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2306.00863">DeepFake-Adapter: Dual-Level Adapter for DeepFake Detection</a>
                </strong>
                <br>
                <br>
                Rui Shao, Tianxing Wu, Liqiang Nie, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.00863">PDF</a>
                    <a href="https://github.com/rshaojimmy/DeepFake-Adapter">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/openood1.5_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2306.09301">OpenOOD v1.5: Enhanced Benchmark for Out-of-Distribution Detection</a>
                </strong>
                <br>
                <br>
                Jingyang Zhang, Jingkang Yang, Pengyun Wang, Haoqi Wang, Yueqian Lin, Haoran Zhang, Yiyou Sun, Xuefeng Du, Kaiyang Zhou, Wayne Zhang, Yixuan Li, <b>Ziwei Liu</b>, Yiran Chen, Hai Li.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.09301">PDF</a>
                    <a href="https://zjysteven.github.io/OpenOOD/">Project Page</a>
                    <a href="https://github.com/Jingkang50/OpenOOD/">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/segsurvey_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2304.09854">Transformer-Based Visual Segmentation: A Survey</a>
                </strong>
                <br>
                <br>
                Xiangtai Li, Henghui Ding, Wenwei Zhang, Haobo Yuan, Jiangmiao Pang, Guangliang Cheng, Kai Chen, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.09854">PDF</a>
                    <a href="https://github.com/lxtGH/Awesome-Segmenation-With-Transformer">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/robobev_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2304.06719">RoboBEV: Towards Robust Bird's Eye View Perception under Corruptions</a>
                </strong>
                <br>
                <br>
                Shaoyuan Xie, Lingdong Kong, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.06719">PDF</a>
                    <a href="https://github.com/Daniel-xsy/RoboBEV">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/consistentnerf_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://skhu101.github.io/ConsistentNeRF/">ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for Sparse View Synthesis</a>
                </strong>
                <br>
                <br>
                Shoukang Hu, Kaichen Zhou, Kaiyu Li, Longhui Yu, Lanqing Hong, Tianyang Hu, Zhenguo Li, Gim Hee Lee, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.11031">PDF</a>
                    <a href="https://skhu101.github.io/ConsistentNeRF/">Project Page</a>
                    <a href="https://github.com/skhu101/ConsistentNeRF">Code</a>
                    <a href="https://www.youtube.com/watch?v=7Ft1S91HxQg">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/reversion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://ziqihuangg.github.io/projects/reversion.html">ReVersion: Diffusion-Based Relation Inversion from Images</a>
                </strong>
                <br>
                <br>
                Ziqi Huang*, Tianxing Wu*, Yuming Jiang, Kelvin C.K. Chan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.13495">PDF</a>
                    <a href="https://ziqihuangg.github.io/projects/reversion.html">Project Page</a>
                    <a href="https://github.com/ziqihuangg/ReVersion">Code</a>
                    <a href="https://www.youtube.com/watch?v=pkal3yjyyKQ">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/proof_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2305.19270">Learning without Forgetting for Vision-Language Models</a>
                </strong>
                <br>
                <br>
                Da-Wei Zhou, Yuanhan Zhang, Jingyi Ning, Han-Jia Ye, De-Chuan Zhan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2305.19270">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/incrementalptm_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2303.07338">Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need</a>
                </strong>
                <br>
                <br>
                Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2303.07338">PDF</a>
                    <a href="https://github.com/zhoudw-zdw/RevisitingCIL">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/incrementalsurvey_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2302.03648">Deep Class-Incremental Learning: A Survey</a>
                </strong>
                <br>
                <br>
                Da-Wei Zhou, Qi-Wei Wang, Zhi-Hong Qi, Han-Jia Ye, De-Chuan Zhan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.03648">PDF</a>
                    <a href="https://github.com/zhoudw-zdw/CIL_Survey/">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/foundationmodel_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2302.09419">A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT</a>
                </strong>
                <br>
                <br>
                Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, Hao Peng, Jianxin Li, Jia Wu, <b>Ziwei Liu</b>, Pengtao Xie, Caiming Xiong, Jian Pei, Philip S. Yu, Lichao Sun.
                <br>
                <em>ArXiv, 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.09419">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/motiondiffuse_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://mingyuan-zhang.github.io/projects/MotionDiffuse.html">MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model</a>
                </strong>
                <br>
                <br>
                Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.15001">PDF</a>
                    <a href="https://mingyuan-zhang.github.io/projects/MotionDiffuse.html">Project Page</a>
                    <a href="https://github.com/mingyuan-zhang/MotionDiffuse">Code</a>
                    <a href="https://www.youtube.com/watch?v=U5PTnw490SA">Demo</a>
                    <a href="https://www.youtube.com/watch?v=-TS2iLhYP28">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/scenedreamer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://scene-dreamer.github.io/">SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, Guangcong Wang, <b>Ziwei Liu</b>.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2302.01330">PDF</a>
                    <a href="https://scene-dreamer.github.io/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/SceneDreamer">Code</a>
                    <a href="https://www.youtube.com/watch?v=nEfSKL2_FoA">Demo</a>
                    <a href="https://80.lv/articles/scenedreamer-unbounded-3d-scene-generation-from-2d-image-collections/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/vrcnet++_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://paul007pl.github.io/projects/VRCNet">Variational Relational Point Completion Network for Robust 3D Classification</a>
                </strong>
                <br>
                <br>
                Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai Yi, <b>Ziwei Liu</b>.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2304.09131">PDF</a>
                    <a href="https://paul007pl.github.io/projects/VRCNet">Project Page</a>
                    <a href="https://github.com/paul007pl/VRCNet">Code</a>
                    <a href="https://mvp-dataset.github.io/">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=8qyhsyis9JY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/c2matching++_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://yumingj.github.io/projects/C2_matching.html">Reference-based Image and Video Super-Resolution via C&sup2;-Matching</a>
                </strong>
                <br>
                <br>
                Yuming Jiang, Kelvin C.K. Chan, Xintao Wang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2212.09581">PDF</a>
                    <a href="https://yumingj.github.io/projects/C2_matching.html">Project Page</a>
                    <a href="https://github.com/yumingj/C2-Matching">Code</a>
                    <a href="https://drive.google.com/drive/folders/1Pt7blJA2cK4oQ6yWB9tcHerZ4pwICmxp?usp=sharing">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/tctrack_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2308.10330">Towards Real-World Visual Tracking with Temporal Contexts</a>
                </strong>
                <br>
                <br>
                Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, <b>Ziwei Liu</b>, Changhong Fu.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2308.10330">PDF</a>
                    <a href="https://github.com/vision4robotics/TCTrack">Code</a>
                    <a href="https://www.youtube.com/watch?v=wcR3iCFJN4E">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unit_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/gpunit/">GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Liming Jiang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2306.04636">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/gpunit/">Project Page</a>
                    <a href="https://github.com/williamyang1991/GP-UNIT">Code</a>
                    <a href="https://www.youtube.com/watch?v=dDApWs_oDrM">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/ssdg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2106.00592">Semi-Supervised Domain Generalization with Stochastic StyleMatch</a>
                </strong>
                <br>
                <br>
                Kaiyang Zhou, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>International Journal of Computer Vision (IJCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2106.00592">PDF</a>
                    <a href="https://github.com/KaiyangZhou/ssdg-benchmark">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fsood_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2204.05306">Full-Spectrum Out-of-Distribution Detection</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Kaiyang Zhou, <b>Ziwei Liu</b>.
                <br>
                <em>International Journal of Computer Vision (IJCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.05306">PDF</a>
                    <a href="https://github.com/Jingkang50/OpenOOD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/3dlifting_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2111.11969">Lifting 2D Human Pose to 3D with Domain Adapted 3D Body Concept</a>
                </strong>
                <br>
                <br>
                Qiang Nie, <b>Ziwei Liu</b>, Yunhui Liu.
                <br>
                <em>International Journal of Computer Vision (IJCV), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2111.11969">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/gai_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2204.05905">Few-shot Forgery Detection via Guided Adversarial Interpolation</a>
                </strong>
                <br>
                <br>
                Haonan Qiu, Siyu Chen, Bei Gan, Kun Wang, Huafeng Shi, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>Pattern Recognition (PR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.05905">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unix_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2012.09413">Computation-Efficient Knowledge Distillation via Uncertainty-Aware Mixup</a>
                </strong>
                <br>
                <br>
                Guodong Xu, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>Pattern Recognition (PR), 2023</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2012.09413">PDF</a>
                    <a href="https://github.com/xuguodong03/UNIXKD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2022</h3>
        <div class="publication">
            <img src="./homepage_files/text2light_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://frozenburning.github.io/projects/text2light/">Text2Light: Zero-Shot Text-Driven HDR Panorama Generation</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, Guangcong Wang, <b>Ziwei Liu</b>.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH Asia), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.09898">PDF</a>
                    <a href="https://frozenburning.github.io/projects/text2light/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/Text2Light">Code</a>
                    <a href="https://www.youtube.com/watch?v=XDx6tOHigPE">Demo</a>
                    <a href="https://www.patreon.com/posts/76349280">Product Transfer</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/vtoonify_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/vtoonify/">VToonify: Controllable High-Resolution Portrait Video Style Transfer</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Liming Jiang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH Asia), 2022</em>
                <br>
                <em><font color="red" size="2">(Selected as TOG Cover)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.11224">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/vtoonify/">Project Page</a>
                    <a href="https://github.com/williamyang1991/VToonify">Code</a>
                    <a href="https://www.youtube.com/watch?v=0_OmVhDgYuY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/maskedlipsync_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/AV-CAT">Masked Lip-Sync Prediction by Uniformed Audio-Visual Context Exploiting with Transformer</a>
                </strong>
                <br>
                <br>
                Yasheng Sun, Hang Zhou, Kaisiyuan Wang, Qianyi Wu, Zhibin Hong, Jingtuo Liu, Jingdong Wang, Errui Ding, <b>Ziwei Liu</b>, Koike Hideki.
                <br>
                <em>SIGGRAPH Asia (Conference Track), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2212.04970">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/AV-CAT">Project Page</a>
                    <a href="https://www.youtube.com/watch?v=o8OtksqC8PY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/angie_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://alvinliu0.github.io/projects/ANGIE">Audio-Driven Co-Speech Gesture Video Generation</a>
                </strong>
                <br>
                <br>
                Xian Liu, Qianyi Wu, Hang Zhou, Yuanqi Du, Wayne Wu, Dahua Lin, <b>Ziwei Liu</b>.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2022 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2212.02350">PDF</a>
                    <a href="https://alvinliu0.github.io/projects/ANGIE">Project Page</a>
                    <a href="https://github.com/alvinliu0/ANGIE">Code</a>
                    <a href="https://github.com/alvinliu0/ANGIE">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=tVclrexHqhs">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/openood_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2210.07242">OpenOOD: Benchmarking Generalized Out-of-Distribution Detection</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Pengyun Wang, Dejian Zou, Zitang Zhou, Kunyuan Ding, Wenxuan Peng, Haoqi Wang, Guangyao Chen, Bo Li, Yiyou Sun, Xuefeng Du, Kaiyang Zhou, Wayne Zhang, Dan Hendrycks, Yixuan Li, <b>Ziwei Liu</b>.
                <br>
                <em>NeurIPS (Datasets and Benchmarks Track), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2210.07242">PDF</a>
                    <a href="https://github.com/Jingkang50/OpenOOD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/hmrbenchmark_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2209.10529">Benchmarking and Analyzing 3D Human Pose and Shape Estimation Beyond Algorithms</a>
                </strong>
                <br>
                <br>
                Hui En Pang, Zhongang Cai, Lei Yang, Tianwei Zhang, <b>Ziwei Liu</b>.
                <br>
                <em>NeurIPS (Datasets and Benchmarks Track), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.10529">PDF</a>
                    <a href="https://github.com/smplbody/hmr-benchmarks">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/animerun_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://lisiyao21.github.io/projects/AnimeRun">AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies</a>
                </strong>
                <br>
                <br>
                Siyao Li, Yuhang Li, Bo Li, Chao Dong, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>NeurIPS (Datasets and Benchmarks Track), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2211.05709">PDF</a>
                    <a href="https://lisiyao21.github.io/projects/AnimeRun">Project Page</a>
                    <a href="https://github.com/lisiyao21/AnimeRun">Code</a>
                    <a href="https://drive.google.com/file/d/1KKuAB_pLuGmRBKjtmYztJnmch2sdi3Qj/view?usp=sharing">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=pCY1axzCnVY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
	    <div class="publication">
            <img src="./homepage_files/humman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://caizhongang.github.io/projects/HuMMan/">HuMMan: Multi-Modal 4D Human Dataset for Versatile Sensing and Modeling</a>
                </strong>
                <br>
                <br>
                Zhongang Cai*, Daxuan Ren*, Ailing Zeng*, Zhengyu Lin*, Tao Yu*, Wenjia Wang*, Xiangyu Fan, Yang Gao, Yifan Yu, Liang Pan, Fangzhou Hong, Mingyuan Zhang, Chen Change Loy, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.13686">PDF</a>
                    <a href="https://caizhongang.github.io/projects/HuMMan/">Project Page</a>
                    <a href="https://github.com/open-mmlab/mmhuman3d">Code</a>
                    <a href="https://caizhongang.github.io/projects/HuMMan/">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=Q_lxIrV3UgE">Demo</a>
                    <a href="https://www.marktechpost.com/2022/05/12/researchers-at-sensetime-develop-humman-a-multi-modal-4d-human-dataset-for-versatile-sensing-and-modeling/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/relighting4d_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://frozenburning.github.io/projects/relighting4d/">Relighting4D: Neural Relightable Human from Videos</a>
                </strong>
                <br>
                <br>
                Zhaoxi Chen, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.07104">PDF</a>
                    <a href="https://frozenburning.github.io/projects/relighting4d/">Project Page</a>
                    <a href="https://github.com/FrozenBurning/Relighting4D">Code</a>
                    <a href="https://www.youtube.com/watch?v=NayAw89qtsY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/psg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://psgdataset.org/">Panoptic Scene Graph Generation</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Yi Zhe Ang, Zujin Guo, Kaiyang Zhou, Wayne Zhang, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.11247">PDF</a>
                    <a href="http://psgdataset.org/">Project Page</a>
                    <a href="https://github.com/Jingkang50/OpenPSG">Code</a>
                    <a href="http://psgdataset.org/">Dataset</a>
                    <a href="https://huggingface.co/spaces/mmlab-ntu/PanopticSceneGraphGeneration">Demo</a>
                    <a href="https://www.youtube.com/watch?v=cSsE_H_0Cr8">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seqdeepfake_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">Detecting and Recovering Sequential DeepFake Manipulation</a>
                </strong>
                <br>
                <br>
                Rui Shao, Tianxing Wu, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.02204">PDF</a>
                    <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">Project Page</a>
                    <a href="https://github.com/rshaojimmy/SeqDeepFake">Code</a>
                    <a href="https://lifehkbueduhk-my.sharepoint.com/:f:/g/personal/16483782_life_hkbu_edu_hk/Evp-uhtWYMBLi9G9JlPcKCEBewkMqPCU69L4Kf29qDQaOw?e=G9JaRm">Dataset</a>
                    <a href="https://news.cgtn.com/news/2022-09-13/-Tech-Please-Are-deepfakes-harming-your-cybersecurity--1diuS6uGXIs/index.html">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/omnibenchmark_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://zhangyuanhan-ai.github.io/OmniBenchmark/">Benchmarking Omni-Vision Representation through the Lens of Visual Realms</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Zhenfei Yin, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.07106">PDF</a>
                    <a href="https://zhangyuanhan-ai.github.io/OmniBenchmark/">Project Page</a>
                    <a href="https://github.com/ZhangYuanhan-AI/OmniBenchmark">Code</a>
                    <a href="https://github.com/ZhangYuanhan-AI/OmniBenchmark">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
         <div class="publication">
            <img src="./homepage_files/stylelight_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://style-light.github.io/">StyleLight: HDR Panorama Generation for Lighting Estimation and Editing</a>
                </strong>
                <br>
                <br>
                Guangcong Wang, Yinuo Yang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.14811">PDF</a>
                    <a href="https://style-light.github.io/">Project Page</a>
                    <a href="https://github.com/Wanggcong/StyleLight">Code</a>
                    <a href="https://www.youtube.com/watch?v=sHeWK1MSPg4">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fastvid2vid_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis</a>
                </strong>
                <br>
                <br>
                Long Zhuo, Guangcong Wang, Shikai Li, Wayne Wu, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.05049">PDF</a>
                    <a href="https://fast-vid2vid.github.io/">Project Page</a>
                    <a href="https://github.com/fast-vid2vid/fast-vid2vid">Code</a>
                    <a href="https://www.youtube.com/watch?v=AhEqjGVuk4A">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/styleganhuman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://stylegan-human.github.io/">StyleGAN-Human: A Data-Centric Odyssey of Human Generation</a>
                </strong>
                <br>
                <br>
                Jianglin Fu*, Shikai Li*, Yuming Jiang, Kwan-Yee Lin, Chen Qian, Chen Change Loy, Wayne Wu, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.11823">PDF</a>
                    <a href="https://stylegan-human.github.io/">Project Page</a>
                    <a href="https://github.com/stylegan-human/StyleGAN-Human">Code</a>
                    <a href="https://github.com/stylegan-human/StyleGAN-Human">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=nIrb9hwsdcI">Demo</a>
                    <a href="https://www.youtube.com/watch?v=smUHQndcmOY">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/celebvhq_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://celebv-hq.github.io/">CelebV-HQ: A Large-Scale Video Facial Attributes Dataset</a>
                </strong>
                <br>
                <br>
                Hao Zhu*, Wayne Wu*, Wentao Zhu, Liming Jiang, Siwei Tang, Li Zhang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.12393">PDF</a>
                    <a href="https://celebv-hq.github.io/">Project Page</a>
                    <a href="https://github.com/CelebV-HQ/CelebV-HQ">Code</a>
                    <a href="https://github.com/CelebV-HQ/CelebV-HQ">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=Y0uxlUW4sW0">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/stylekd_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2208.08840">Mind the Gap in Distilling StyleGANs</a>
                </strong>
                <br>
                <br>
                Guodong Xu, Yuenan Hou, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.08840">PDF</a>
                    <a href="https://github.com/xuguodong03/StyleKD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unif_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://shenhanqian.com/unif">UNIF: United Neural Implicit Functions for Clothed Human Reconstruction and Animation</a>
                </strong>
                <br>
                <br>
                Shenhan Qian, Jiale Xu, <b>Ziwei Liu</b>, Liqian Ma, Shenghua Gao.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.09835">PDF</a>
                    <a href="https://shenhanqian.com/unif">Project Page</a>
                    <a href="https://github.com/ShenhanQian/UNIF">Code</a>
                    <a href="https://www.youtube.com/watch?v=2w4sYMLFHKM">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/xlearner_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2203.08764">X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation</a>
                </strong>
                <br>
                <br>
                Yinan He, Gengshi Huang, Siyu Chen, Jianing Teng, Wang Kun, Zhenfei Yin, Lu Sheng, <b>Ziwei Liu</b>, Yu Qiao, Jing Shao.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.08764">PDF</a>
                    <a href="https://opengvlab.shlab.org.cn/home">Project Page</a>
                    <a href="https://github.com/OpenGVLab">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/styleswap_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/StyleSwap">StyleSwap: Style-Based Generator Empowers Robust Face Swapping</a>
                </strong>
                <br>
                <br>
                Zhiliang Xu, Hang Zhou, Zhibin Hong, <b>Ziwei Liu</b>, Jiaming Liu, Zhizhi Guo, Junyu Han, Jingtuo Liu, Errui Ding, Jingdong Wang.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.13514">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/StyleSwap">Project Page</a>
                    <a href="https://github.com/Seanseattle/StyleSwap">Code</a>
                    <a href="https://www.youtube.com/watch?v=bsHhzU8VSLo">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/avatarclip_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hongfz16.github.io/projects/AvatarCLIP.html">AvatarCLIP: Zero-Shot Text-Driven Generation and Animation of 3D Avatars</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong*, Mingyuan Zhang*, Liang Pan, Zhongang Cai, Lei Yang, <b>Ziwei Liu</b>.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2205.08535">PDF</a>
                    <a href="https://hongfz16.github.io/projects/AvatarCLIP.html">Project Page</a>
                    <a href="https://github.com/hongfz16/AvatarCLIP">Code</a>
                    <a href="https://www.youtube.com/watch?v=-l2ZMeoASGY">Demo</a>
                    <a href="https://www.marktechpost.com/2022/06/29/ntu-researchers-propose-avatarclip-a-novel-zero-shot-text-driven-3d-avatar-generation-and-animation-pipeline/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/text2human_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://yumingj.github.io/projects/Text2Human.html">Text2Human: Text-Driven Controllable Human Image Generation</a>
                </strong>
                <br>
                <br>
                Yuming Jiang, Shuai Yang, Haonan Qiu, Wayne Wu, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2205.15996">PDF</a>
                    <a href="https://yumingj.github.io/projects/Text2Human.html">Project Page</a>
                    <a href="https://github.com/yumingj/Text2Human">Code</a>
                    <a href="https://github.com/yumingj/DeepFashion-MultiModal">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=yKh4VORA_E0">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/modelnetc_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://pointcloud-c.github.io/home.html">Benchmarking and Analyzing Point Cloud Classification under Corruptions</a>
                </strong>
                <br>
                <br>
                Jiawei Ren, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Machine Learning (ICML), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2202.03377">PDF</a>
                    <a href="https://pointcloud-c.github.io/home.html">Project Page</a>
                    <a href="https://github.com/ldkong1205/PointCloud-C">Code</a>
                    <a href="https://paperswithcode.com/dataset/pointcloud-c">Dataset</a>
                    <a href="https://huggingface.co/spaces/ICML2022/PointCloudC">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/hcmoco_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hongfz16.github.io/projects/HCMoCo.html">Versatile Multi-Modal Pre-Training for Human-Centric Perception</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong, Liang Pan, Zhongang Cai, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.13815">PDF</a>
                    <a href="https://hongfz16.github.io/projects/HCMoCo.html">Project Page</a>
                    <a href="https://github.com/hongfz16/HCMoCo">Code</a>
                    <a href="https://github.com/hongfz16/HCMoCo/tree/main/pycontrast/data/NTURGBD-Parsing-4K">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/balancedmse_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://sites.google.com/view/balanced-mse/home">Balanced MSE for Imbalanced Visual Regression</a>
                </strong>
                <br>
                <br>
                Jiawei Ren, Mingyuan Zhang, Cunjun Yu, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.16427">PDF</a>
                    <a href="https://sites.google.com/view/balanced-mse/home">Project Page</a>
                    <a href="https://github.com/jiawei-ren/BalancedMSE">Code</a>
                    <a href="https://www.youtube.com/watch?v=erw9qaAyCPA">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/bailando_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/bailando/">Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory</a>
                </strong>
                <br>
                <br>
                Siyao Li, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.13055">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/bailando/">Project Page</a>
                    <a href="https://github.com/lisiyao21/Bailando/">Code</a>
                    <a href="https://www.youtube.com/watch?v=YbXOcuMTzD8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/cocoop_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2203.05557">Conditional Prompt Learning for Vision-Language Models</a>
                </strong>
                <br>
                <br>
                Kaiyang Zhou, Jingkang Yang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.05557">PDF</a>
                    <a href="https://github.com/KaiyangZhou/CoOp">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/transda_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2106.07617">Delving Deep into the Generalization of Vision Transformers under Distribution Shifts</a>
                </strong>
                <br>
                <br>
                Chongzhi Zhang*, Mingyuan Zhang*, Shanghang Zhang*, Daisheng Jin, Qiang Zhou, Zhongang Cai, Haiyu Zhao, Shuai Yi, Xianglong Liu, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2106.07617">PDF</a>
                    <a href="https://github.com/Phoenix1153/ViT_OOD_generalization">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/vton_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://lzqhardworker.github.io/RT-VTON/">Full-Range Virtual Try-On with Recurrent Tri-Level Transformation</a>
                </strong>
                <br>
                <br>
                Han Yang, Xinrui Yu, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.pdf">PDF</a>
                    <a href="https://lzqhardworker.github.io/RT-VTON/">Project Page</a>
                    <a href="https://www.youtube.com/watch?v=2XoW-HcrevM">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unit_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/gpunit/">Unsupervised Image-to-Image Translation with Generative Prior</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Liming Jiang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.03641">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/gpunit/">Project Page</a>
                    <a href="https://github.com/williamyang1991/GP-UNIT">Code</a>
                    <a href="https://www.youtube.com/watch?v=dDApWs_oDrM">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pastiche_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/dualstylegan/">Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer</a>
                </strong>
                <br>
                <br>
                Shuai Yang, Liming Jiang, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.13248">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/dualstylegan/">Project Page</a>
                    <a href="https://github.com/williamyang1991/DualStyleGAN">Code</a>
                    <a href="https://www.youtube.com/watch?v=scZTu77jixI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/tctrack_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2203.01885">TCTrack: Temporal Contexts for Aerial Tracking</a>
                </strong>
                <br>
                <br>
                Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, <b>Ziwei Liu</b>, Changhong Fu.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.01885">PDF</a>
                    <a href="https://github.com/vision4robotics/TCTrack">Code</a>
                    <a href="https://www.youtube.com/watch?v=wcR3iCFJN4E">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/tada_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://tadaconv-iclr2022.github.io/">TAda! Temporally-Adaptive Convolutions for Video Understanding</a>
                </strong>
                <br>
                <br>
                Ziyuan Huang, Shiwei Zhang, Liang Pan, Zhiwu Qing, Mingqian Tang, <b>Ziwei Liu</b>, Marcelo H. Ang Jr.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2110.06178">PDF</a>
                    <a href="https://tadaconv-iclr2022.github.io/">Project Page</a>
                    <a href="https://github.com/alibaba-mmai-research/TAdaConv">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/bibert_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://openreview.net/pdf?id=5xEgrl_5FAJ">BiBERT: Accurate Fully Binarized BERT</a>
                </strong>
                <br>
                <br>
                Haotong Qin, Yifu Ding, Mingyuan Zhang, Qinghua Yan, Aishan Liu, Qingqing Dang, <b>Ziwei Liu</b>, Xianglong Liu.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openreview.net/pdf?id=5xEgrl_5FAJ">PDF</a>
                    <a href="https://github.com/htqin/BiBERT">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/soundloc_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2202.06406">Visual Sound Localization in-the-Wild by Cross-Modal Interference Erasing</a>
                </strong>
                <br>
                <br>
                Xian Liu, Rui Qian, Hang Zhou, Weiyao Lin, <b>Ziwei Liu</b>, Bolei Zhou, Xiaowei Zhou.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2202.06406">PDF</a>
                    <a href="https://github.com/alvinliu0/Visual-Sound-Localization-in-the-Wild">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/sepfusion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.aaai.org/AAAI22Papers/AAAI-11517.ZhouD.pdf">SepFusion: Finding Optimal Fusion Structures for Visual Sound Separation</a>
                </strong>
                <br>
                <br>
                Dongzhan Zhou, Xinchi Zhou, Di Hu, Hang Zhou, Lei Bai, <b>Ziwei Liu</b>, Wanli Ouyang.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.aaai.org/AAAI22Papers/AAAI-11517.ZhouD.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/surgicalvideo_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2205.09292">Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions</a>
                </strong>
                <br>
                <br>
                Xinpeng Ding, <b>Ziwei Liu</b>, Xiaomeng Li.
                <br>
                <em>Medical Image Comp. and Computer Assisted Interv. (MICCAI), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2205.09292">PDF</a>
                    <a href="https://github.com/xmed-lab/DistillingSelf">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/modelnetc_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://pointcloud-c.github.io/home.html">PointCloud-C: Benchmarking and Analyzing Point Cloud Perception Robustness under Corruptions</a>
                </strong>
                <br>
                <br>
                Jiawei Ren*, Lingdong Kong*, Liang Pan, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://pointcloud-c.github.io/asset/2022_PointCloud-C_preprint.pdf">PDF</a>
                    <a href="https://pointcloud-c.github.io/home.html">Project Page</a>
                    <a href="https://github.com/ldkong1205/PointCloud-C">Code</a>
                    <a href="https://paperswithcode.com/dataset/pointcloud-c">Dataset</a>
                    <a href="https://huggingface.co/spaces/ICML2022/PointCloudC">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/triplee_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2210.01807">TripleE: Easy Domain Generalization via Episodic Replay</a>
                </strong>
                <br>
                <br>
                Xiaomeng Li, Hongyu Ren, Huifeng Yao, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2210.01807">PDF</a>
                    <a href="https://github.com/xmed-lab/triplee-dg">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/oddg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2209.07521">On-Device Domain Generalization</a>
                </strong>
                <br>
                <br>
                Kaiyang Zhou, Yuanhan Zhang, Yuhang Zang, Jingkang Yang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2209.07521">PDF</a>
                    <a href="https://github.com/KaiyangZhou/on-device-dg">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/stylefacev_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://haonanqiu.com/projects/StyleFaceV.html">StyleFaceV: Face Video Generation via Decomposing and Recomposing Pretrained StyleGAN3</a>
                </strong>
                <br>
                <br>
                Haonan Qiu, Yuming Jiang, Hang Zhou, Wayne Wu, <b>Ziwei Liu</b>.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.07862">PDF</a>
                    <a href="http://haonanqiu.com/projects/StyleFaceV.html">Project Page</a>
                    <a href="https://github.com/arthur-qiu/StyleFaceV">Code</a>
                    <a href="https://www.youtube.com/watch?v=BZNLcD04-Fc">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/noah_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://zhangyuanhan-ai.github.io/NOAH/">Neural Prompt Search</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Kaiyang Zhou, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2206.04673">PDF</a>
                    <a href="https://zhangyuanhan-ai.github.io/NOAH/">Project Page</a>
                    <a href="https://github.com/Davidzhangyuanhan/NOAH">Code</a>
                    <a href="https://www.marktechpost.com/2022/06/21/ntu-researchers-propose-noah-neural-prompt-search-for-large-vision-models/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/bamboo_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://opengvlab.shlab.org.cn/bamboo/home">Bamboo: Building Mega-Scale Vision Dataset Continually with Human-Machine Synergy</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Qinghong Sun, Yichun Zhou, Zexin He, Zhenfei Yin, Kun Wang, Lu Sheng, Yu Qiao, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.07845">PDF</a>
                    <a href="https://opengvlab.shlab.org.cn/bamboo/home">Project Page</a>
                    <a href="https://github.com/Davidzhangyuanhan/Bamboo">Code</a>
                    <a href="https://opengvlab.shlab.org.cn/bamboo/home">Dataset</a>
                    <a href="https://huggingface.co/spaces/CVPR/Bamboo_ViT-B16_demo">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dpm_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2204.12685">Robust Face Anti-Spoofing with Dual Probabilistic Modeling</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Yichao Wu, Zhenfei Yin, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2204.12685">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dsnet4d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2203.07186">Unified 3D and 4D Panoptic Segmentation via Dynamic Shifting Network</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong, Hui Zhou, Xinge Zhu, Hongsheng Li, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2203.07186">PDF</a>
                    <a href="https://github.com/hongfz16/DS-Net">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pointregistration_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2111.15606">Robust Partial-to-Partial Point Cloud Registration in a Full Range</a>
                </strong>
                <br>
                <br>
                Liang Pan, Zhongang Cai, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2111.15606">PDF</a>
                    <a href="https://github.com/paul007pl/GMCNet">Code</a>
                    <a href="https://mvp-dataset.github.io/MVP/Registration.html">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/play3dhuman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://caizhongang.github.io/projects/GTA-Human/">Playing for 3D Human Recovery</a>
                </strong>
                <br>
                <br>
                Zhongang Cai*, Mingyuan Zhang*, Jiawei Ren*, Chen Wei, Daxuan Ren, Jiatong Li, Zhengyu Lin, Haiyu Zhao, Shuai Yi, Lei Yang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2110.07588">PDF</a>
                    <a href="https://caizhongang.github.io/projects/GTA-Human/">Project Page</a>
                    <a href="https://github.com/open-mmlab/mmhuman3d">Code</a>
                    <a href="https://caizhongang.github.io/projects/GTA-Human/">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=ywSJyuk_MTU">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/oodsurvey_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2110.11334">Generalized Out-of-Distribution Detection: A Survey</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Kaiyang Zhou, Yixuan Li, <b>Ziwei Liu</b>.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2110.11334">PDF</a>
                    <a href="https://github.com/Jingkang50/OODSurvey">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pttr++_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2208.05216">Exploring Point-BEV Fusion for 3D Point Cloud Object Tracking with Transformer</a>
                </strong>
                <br>
                <br>
                Zhipeng Luo, Changqing Zhou, Liang Pan, Gongjie Zhang, Tianrui Liu, Yueru Luo, Haiyu Zhao, <b>Ziwei Liu</b>, Shijian Lu.
                <br>
                <em>ArXiv, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.05216">PDF</a>
                    <a href="https://github.com/Jasonkks/PTTR">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/oltr++_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://liuziwei7.github.io/projects/LongTail.html">Open Long-Tailed Recognition in a Dynamic World</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Zhongqi Miao*, Xiaohang Zhan, Jiayun Wang, Boqing Gong, Stella X. Yu.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2208.08349">PDF</a>
                    <a href="https://liuziwei7.github.io/projects/LongTail.html">Project Page</a>
                    <a href="https://github.com/zhmiao/OpenLongTailRecognition-OLTR">Code</a>
                    <a href="https://www.youtube.com/watch?v=A45wrs1g8VA">Demo</a>
                    <a href="https://bair.berkeley.edu/blog/2019/05/13/oltr/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/domaingeneralization_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2103.02503">Domain Generalization: A Survey</a>
                </strong>
                <br>
                <br>
                Kaiyang Zhou, <b>Ziwei Liu</b>, Yu Qiao, Tao Xiang, Chen Change Loy.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2103.02503">PDF</a>
                    <a href="https://github.com/KaiyangZhou/Dassl.pytorch">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/coop_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2109.01134">Learning to Prompt for Vision-Language Models</a>
                </strong>
                <br>
                <br>
                Kaiyang Zhou, Jingkang Yang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>International Journal of Computer Vision (IJCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2109.01134">PDF</a>
                    <a href="https://github.com/KaiyangZhou/CoOp">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/interclr_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/open-mmlab/OpenSelfSup">Delving into Inter-Image Invariance for Unsupervised Visual Representations</a>
                </strong>
                <br>
                <br>
                Jiahao Xie, Xiaohang Zhan, <b>Ziwei Liu</b>, Yew-Soon Ong, Chen Change Loy.
                <br>
                <em>International Journal of Computer Vision (IJCV), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2008.11702">PDF</a>
                    <a href="https://github.com/open-mmlab/mmselfsup">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/tailhuman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://penincillin.github.io/pmnet_tip2022">Chasing the Tail in Monocular 3D Human Reconstruction with Prototype Memory</a>
                </strong>
                <br>
                <br>
                Yu Rong, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>IEEE Transactions on Image Processing (TIP), 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2012.14739">PDF</a>
                    <a href="https://penincillin.github.io/pmnet_tip2022">Project Page</a>
                    <a href="https://github.com/penincillin/PMNet">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mvpchallenge_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://competitions.codalab.org/competitions/33430">Multi-View Partial (MVP) Point Cloud Challenge 2021 on Completion and Registration: Methods and Results</a>
                </strong>
                <br>
                <br>
                Liang Pan, Tong Wu, Zhongang Cai, <b>Ziwei Liu</b>, et al.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2112.12053">PDF</a>
                    <a href="https://competitions.codalab.org/competitions/33430">Project Page</a>
                    <a href="https://github.com/paul007pl/MVP_Benchmark">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/forgerychallenge_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://competitions.codalab.org/competitions/33386">ForgeryNet - Face Forgery Analysis Challenge 2021: Methods and Results</a>
                </strong>
                <br>
                <br>
                Yinan He, Lu Sheng, Jing Shao, <b>Ziwei Liu</b>, et al.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2112.08325">PDF</a>
                    <a href="https://competitions.codalab.org/competitions/33386">Project Page</a>
                    <a href="https://github.com/yinanhe/ForgeryNet">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/multiforgery_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://tianchi.aliyun.com/competition/entrance/531954/introduction">Multi-Forgery Detection Challenge 2022: Push the Frontier of Unconstrained and Diverse Forgery Detection</a>
                </strong>
                <br>
                <br>
                Jianshu Li, Man Luo, Jian Liu, Tao Chen, Chengjie Wang, <b>Ziwei Liu</b>, et al.
                <br>
                <em>arXiv Preprint, 2022</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2207.13505">PDF</a>
                    <a href="https://tianchi.aliyun.com/competition/entrance/531954/introduction">Project Page</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2021</h3>
        <div class="publication">
            <img src="./homepage_files/activewild_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.nature.com/articles/s42256-021-00393-0">Iterative Human and Automated Identification of Wildlife Images</a>
                </strong>
                <br>
                <br>
                Zhongqi Miao*, <b>Ziwei Liu*</b>, Kaitlyn M. Gaynor, Meredith S. Palmer, Stella X. Yu, Wayne M. Getz.
                <br>
                <em>Nature - Machine Intelligence, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.nature.com/articles/s42256-021-00393-0">PDF</a>
                    <a href="https://github.com/zhmiao/AnimalActiveLearning">Code</a>
                    <a href="https://lilablobssc.blob.core.windows.net/gorongosacameratraps/gorongosa-camera-traps-public-256x256.zip">Dataset</a>
                    <a href="https://codeocean.com/capsule/2011717/tree/v1">Demo</a>
                    <a href="https://bair.berkeley.edu/blog/2022/05/03/human-in-the-loop/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/garment4d_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hongfz16.github.io/projects/Garment4D.html">Garment4D: Garment Reconstruction from Point Cloud Sequences</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong, Liang Pan, Zhongang Cai, <b>Ziwei Liu</b>.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2112.04159">PDF</a>
                    <a href="https://hongfz16.github.io/projects/Garment4D.html">Project Page</a>
                    <a href="https://github.com/hongfz16/Garment4D">Code</a>
                    <a href="https://www.youtube.com/watch?v=zEYQxN8vOfw">Demo</a>
                    <a href="https://www.marktechpost.com/2021/12/30/researchers-develop-garment4d-a-garment-reconstruction-model-using-point-cloud-sequences/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/bcd_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2111.12702">Density-aware Chamfer Distance as a Comprehensive Metric for Point Cloud Completion</a>
                </strong>
                <br>
                <br>
                Tong Wu, Liang Pan, Junzhe Zhang, Tai Wang, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2111.12702">PDF</a>
                    <a href="https://github.com/wutong16/Density_aware_Chamfer_Distance">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fadi_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2111.11656">Few-Shot Object Detection via Association and DIscrimination</a>
                </strong>
                <br>
                <br>
                Yuhang Cao, Jiaqi Wang, Ying Jin, Tong Wu, Kai Chen, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2111.11656">PDF</a>
                    <a href="https://github.com/yhcao6/FADI">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/orl_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/orl/">Unsupervised Object-Level Representation Learning from Scene Images</a>
                </strong>
                <br>
                <br>
                Jiahao Xie, Xiaohang Zhan, <b>Ziwei Liu</b>, Yew-Soon Ong, Chen Change Loy.
                <br>
                <em>Neural Information Processing Systems (NeurIPS), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2106.11952">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/orl/">Project Page</a>
                    <a href="https://github.com/Jiahao000/ORL">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/talkedit_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.mmlab-ntu.com/project/talkedit/">Talk-to-Edit: Fine-Grained Facial Editing via Dialog</a>
                </strong>
                <br>
                <br>
                Yuming Jiang*, Ziqi Huang*, Xingang Pan, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2109.04425">PDF</a>
                    <a href="https://www.mmlab-ntu.com/project/talkedit/">Project Page</a>
                    <a href="https://github.com/yumingj/Talk-to-Edit">Code</a>
                    <a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA/CelebA_Dialog.html">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/scood_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://jingkang50.github.io/projects/scood">Semantically Coherent Out-of-Distribution Detection</a>
                </strong>
                <br>
                <br>
                Jingkang Yang, Haoqi Wang, Litong Feng, Xiaopeng Yan, Huabin Zheng, Wayne Zhang, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2108.11941">PDF</a>
                    <a href="https://jingkang50.github.io/projects/scood">Project Page</a>
                    <a href="https://github.com/jingkang50/ICCV21_SCOOD">Code</a>
                    <a href="https://drive.google.com/file/d/1cbLXZ39xnJjxXnDM7g2KODHIjE0Qj4gu/view?usp=sharing">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/da3ddet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2107.11355">Unsupervised Domain Adaptive 3D Detection with Multi-Level Consistency</a>
                </strong>
                <br>
                <br>
                Zhipeng Luo, Zhongang Cai, Changqing Zhou, Gongjie Zhang, Haiyu Zhao, Shuai Yi, Shijian Lu, Hongsheng Li, Shanghang Zhang, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2107.11355">PDF</a>
                    <a href="https://github.com/Jasonkks/mlcnet">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dynamicwirings_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yuan_Differentiable_Dynamic_Wirings_for_Neural_Networks_ICCV_2021_paper.pdf">Differentiable Dynamic Wirings for Neural Networks</a>
                </strong>
                <br>
                <br>
                Kun Yuan, Quanquan Li, Shaopeng Guo, Dapeng Chen, Aojun Zhou, Fengwei Yu, <b>Ziwei Liu</b>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yuan_Differentiable_Dynamic_Wirings_for_Neural_Networks_ICCV_2021_paper.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/ceit_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2103.11816">Incorporating Convolution Designs into Visual Transformers</a>
                </strong>
                <br>
                <br>
                Kun Yuan, Shaopeng Guo, <b>Ziwei Liu</b>, Aojun Zhou, Fengwei Yu, Wei Wu.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2103.11816">PDF</a>
                    <a href="https://github.com/coeusguo/ceit">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/eow_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2107.12628">Energy-Based Open-World Uncertainty Modeling for Confidence Calibration</a>
                </strong>
                <br>
                <br>
                Yezhen Wang, Bo Li, Tong Che, Kaiyang Zhou, <b>Ziwei Liu</b>, Dongsheng Li.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2107.12628">PDF</a>
                    <a href="https://github.com/BIGKnight/Energy-Based-Open-World-Uncertainty-Modeling-for-Confidence-Calibration">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/blockplanner_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://city-super.github.io/blockplanner/">BlockPlanner: City Block Generation with Vectorized Graph Representation</a>
                </strong>
                <br>
                <br>
                Linning Xu, Yuanbo Xiangli, Anyi Rao, Nanxuan Zhao, Bo Dai, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_BlockPlanner_City_Block_Generation_With_Vectorized_Graph_Representation_ICCV_2021_paper.pdf">PDF</a>
		    <a href="https://city-super.github.io/blockplanner/">Project Page</a>
		    <a href="https://github.com/city-super/blockplanner">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/vrcnet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://paul007pl.github.io/projects/VRCNet">Variational Relational Point Completion Network</a>
                </strong>
                <br>
                <br>
                Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai Yi, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2104.10154">PDF</a>
                    <a href="https://paul007pl.github.io/projects/VRCNet">Project Page</a>
                    <a href="https://github.com/paul007pl/VRCNet">Code</a>
                    <a href="https://mvp-dataset.github.io/">Dataset</a>
                    <a href="https://www.youtube.com/watch?v=8qyhsyis9JY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/forgerynet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://yinanhe.github.io/projects/forgerynet.html">ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis</a>
                </strong>
                <br>
                <br>
                Yinan He*, Bei Gan*, Siyu Chen*, Yichun Zhou*, Guojun Yin, Luchuan Song, Lu Sheng, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2103.05630">PDF</a>
                    <a href="https://yinanhe.github.io/projects/forgerynet.html">Project Page</a>
                    <a href="https://github.com/yinanhe/forgerynet">Code</a>
                    <a href="https://www.youtube.com/watch?v=e8XIL3Di2Y8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/advlongtail_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2104.02703">Adversarial Robustness under Long-Tailed Distribution</a>
                </strong>
                <br>
                <br>
                Tong Wu, <b>Ziwei Liu</b>, Qingqiu Huang, Yu Wang, Dahua Lin.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2104.02703">PDF</a>
                    <a href="https://github.com/wutong16/Adversarial_Long-Tail">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dsnet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2011.11964">LiDAR-based Panoptic Segmentation via Dynamic Shifting Network</a>
                </strong>
                <br>
                <br>
                Fangzhou Hong, Hui Zhou, Xinge Zhu, Hongsheng Li, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021 <font color="#e86e14">(Winning Entry of SemanticKITTI Panoptic Segmentation Track)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2011.11964">PDF</a>
                    <a href="https://github.com/hongfz16/DS-Net">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/c2matching_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://yumingj.github.io/projects/C2_matching.html">Robust Reference-based Super-Resolution via C&sup2;-Matching</a>
                </strong>
                <br>
                <br>
                Yuming Jiang, Kelvin C.K. Chan, Xintao Wang, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2106.01863">PDF</a>
                    <a href="https://yumingj.github.io/projects/C2_matching.html">Project Page</a>
                    <a href="https://github.com/yumingj/C2-Matching">Code</a>
                    <a href="https://drive.google.com/drive/folders/1Pt7blJA2cK4oQ6yWB9tcHerZ4pwICmxp?usp=sharing">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pctalkingface_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS">Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation</a>
                </strong>
                <br>
                <br>
                Hang Zhou, Yasheng Sun, Wayne Wu, Chen Change Loy, Xiaogang Wang, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2104.11116">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS">Project Page</a>
                    <a href="https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS">Code</a>
                    <a href="https://www.youtube.com/watch?v=lNQQHIggnUg">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/animeinterp_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2104.02495">Deep Animation Video Interpolation in the Wild</a>
                </strong>
                <br>
                <br>
                Siyao Li*, Shiyu Zhao*, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2104.02495">PDF</a>
                    <a href="https://github.com/lisiyao21/AnimeInterp/">Code</a>
                    <a href="https://www.youtube.com/watch?v=2bbujT-ZXr8">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/binaural_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://sheldontsui.github.io/projects/PseudoBinaural">Visually Informed Binaural Audio Generation without Binaural Audios</a>
                </strong>
                <br>
                <br>
                Xudong Xu*, Hang Zhou*, <b>Ziwei Liu</b>, Bo Dai, Xiaogang Wang, Dahua Lin.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2104.06162">PDF</a>
                    <a href="https://sheldontsui.github.io/projects/PseudoBinaural">Project Page</a>
                    <a href="https://github.com/SheldonTsui/PseudoBinaural_CVPR2021">Code</a>
                    <a href="https://www.youtube.com/watch?v=r-uC2MyAWQc">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/seesawloss_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/open-mmlab/mmdetection">Seesaw Loss for Long-Tailed Instance Segmentation</a>
                </strong>
                <br>
                <br>
                Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, <b>Ziwei Liu</b>, Chen Change Loy, Dahua Lin.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2008.10032">PDF</a>
                    <a href="https://github.com/open-mmlab/mmdetection">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/crossdiscrimination_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://people.eecs.berkeley.edu/~xdwang/projects/CLD/">Unsupervised Feature Learning by Cross-Level Instance-Group Discrimination</a>
                </strong>
                <br>
                <br>
                Xudong Wang, <b>Ziwei Liu</b>, Stella X. Yu.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2008.03813">PDF</a>
                    <a href="http://people.eecs.berkeley.edu/~xdwang/projects/CLD/">Project Page</a>
                    <a href="https://github.com/frank-xwang/CLD-UnsupervisedLearning">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/gan2shape_logo.gif" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://xingangpan.github.io/projects/GAN2Shape.html">Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs</a>
                </strong>
                <br>
                <br>
                Xingang Pan, Bo Dai, <b>Ziwei Liu</b>, Chen Change Loy, Ping Luo.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2021 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2011.00844">PDF</a>
                    <a href="https://xingangpan.github.io/projects/GAN2Shape.html">Project Page</a>
                    <a href="https://github.com/XingangPan/GAN2Shape">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/ride_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://people.eecs.berkeley.edu/~xdwang/projects/RIDE/">Long-Tailed Recognition by Routing Diverse Distribution-Aware Experts</a>
                </strong>
                <br>
                <br>
                Xudong Wang, Long Lian, Zhongqi Miao, <b>Ziwei Liu</b>, Stella X. Yu.
                <br>
                <em>Inter. Conference on Learning Representations (ICLR), 2021 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2010.01809">PDF</a>
                    <a href="http://people.eecs.berkeley.edu/~xdwang/projects/RIDE/">Project Page</a>
                    <a href="https://github.com/frank-xwang/RIDE-LongTailRecognition">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/carafe++_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2012.04733">CARAFE++: Unified Content-Aware ReAssembly of FEatures</a>
                </strong>
                <br>
                <br>
                Jiaqi Wang, Kai Chen, Rui Xu, <b>Ziwei Liu</b>, Chen Change Loy, Dahua Lin.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2012.04733">PDF</a>
                    <a href="https://github.com/open-mmlab/mmdetection">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pteacher_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://dl.acm.org/doi/10.1145/3411764.3445490">PTeacher: a Computer-Aided Personalized Pronunciation Training System with Exaggerated Audio-Visual Corrective Feedback</a>
                </strong>
                <br>
                <br>
                Yaohua Bu*, Tianyi Ma*, Weijun Li, Hang Zhou, Jia Jia, Shengqi Chen, Kaiyuan Xu, Dachuan Shi, Haozhe Wu, Zhihan Yang, Kun Li, Zhiyong Wu, Yuanchun Shi, Xiaobo Lu, <b>Ziwei Liu</b>.
                <br>
                <em>ACM Conference on Human Factors in Computing Systems (CHI), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://dl.acm.org/doi/10.1145/3411764.3445490">PDF</a>
                    <a href="https://www.youtube.com/watch?v=AeDKn5DwVfI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/3dhand_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://penincillin.github.io/ihmr_3dv2021">Monocular 3D Reconstruction of Interacting Hands via Collision-Aware Factorized Refinements</a>
                </strong>
                <br>
                <br>
                Yu Rong,  Jingbo Wang,  <b>Ziwei Liu</b>,  Chen Change Loy.
                <br>
                <em>International Conference on 3D Vision (3DV), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2111.00763">PDF</a>
                    <a href="https://penincillin.github.io/ihmr_3dv2021">Project Page</a>
                    <a href="https://github.com/penincillin/IHMR">Code</a>
                    <a href="https://www.youtube.com/watch?v=OR_29xBOHn0">Demo</a>
                    <a href="https://todayheadline.co/monocular-3d-reconstruction-of-interacting-hands-via-collision-aware-factorized-refinements/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/speech2talkingface_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.ijcai.org/proceedings/2021/0141.pdf">Speech2Talking-Face: Inferring and Driving a Face with Synchronized Audio-Visual Representation</a>
                </strong>
                <br>
                <br>
                Yasheng Sun*, Hang Zhou*, <b>Ziwei Liu</b>, Hideki Koike.
                <br>
                <em>International Joint Conference on Artificial Intelligence (IJCAI), 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.ijcai.org/proceedings/2021/0141.pdf">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/personincontext_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2008.12679">Person-in-Context Synthesis with Compositional Structural Space</a>
                </strong>
                <br>
                <br>
                Weidong Yin, <b>Ziwei Liu</b>, Leonid Sigal.
                <br>
                <em>Winter Conf. on Applications of Computer Vision (WACV), 2021 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2008.12679">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/videotryon_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://gauravkuppa.github.io/publication/2021-01-09-shine-on-1">ShineOn: Illuminating Design Choices for Practical Video-based Virtual Clothing Try-on</a>
                </strong>
                <br>
                <br>
                Gaurav Kuppa, Andrew Jong, Vera Liu, <b>Ziwei Liu</b>, Teng-Sheng Moh.
                <br>
                <em>WACV Workshop on Generation of Human Behavior, 2021 <font color="#e86e14">(Winning Entry)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2012.10495">PDF</a>
                    <a href="https://gauravkuppa.github.io/publication/2021-01-09-shine-on-1">Project Page</a>
                    <a href="https://github.com/andrewjong/ShineOn-Virtual-Tryon">Code</a>
                    <a href="https://docs.google.com/presentation/d/1o6oMOU8Azy7O4x_T3eJM-wsoe6ZTv4Hoxk3oly9ITuk/edit?usp=sharing">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mmfashion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/open-mmlab/mmfashion">MMFashion: An Open-Source Toolbox for Visual Fashion Analysis</a>
                </strong>
                <br>
                <br>
                Xin Liu, Jiancheng Li, Jiaqi Wang, <b>Ziwei Liu</b>.
                <br>
                <em>ACM Multimedia (ACM MM), 2021 <font color="#e86e14">(Open Source Software Competition)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2005.08847">PDF</a>
                    <a href="https://github.com/open-mmlab/mmfashion">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/spoofchallenge_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://competitions.codalab.org/competitions/25228">CelebA-Spoof Challenge 2020 on Face Anti-Spoofing: Methods and Results</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang, Zhenfei Yin, Jing Shao, <b>Ziwei Liu</b>, et al.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2102.12642">PDF</a>
                    <a href="https://competitions.codalab.org/competitions/26210">Project Page</a>
                    <a href="https://github.com/Davidzhangyuanhan/CelebA-Spoof">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deeperforensics_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://competitions.codalab.org/competitions/25228">DeeperForensics Challenge 2020 on Real-World Face Forgery Detection: Methods and Results</a>
                </strong>
                <br>
                <br>
                Liming Jiang, Zhengkui Guo, Wayne Wu, Zhaoyang Liu, <b>Ziwei Liu</b>, Chen Change Loy, et al.
                <br>
                <em>arXiv Preprint, 2021</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2102.09471">PDF</a>
                    <a href="https://competitions.codalab.org/competitions/25228">Project Page</a>
                    <a href="https://github.com/EndlessSora/DeeperForensics-1.0">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2020</h3>
        <div class="publication">
            <img src="./homepage_files/multilabel_longtail_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2007.09654">Distribution-Balanced Loss for Multi-Label Classification in Long-Tailed Datasets</a>
                </strong>
                <br>
                <br>
                Tong Wu, Qingqiu Huang, <b>Ziwei Liu</b>, Yu Wang, Dahua Lin.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.09654">PDF</a>
                    <a href="https://github.com/wutong16/DistributionBalancedLoss">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/celebaspoof_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/Davidzhangyuanhan/CelebA-Spoof">CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich Annotations</a>
                </strong>
                <br>
                <br>
                Yuanhan Zhang*, Zhenfei Yin*, Yidong Li, Guojun Yin, Junjie Yan, Jing Shao, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.12342">PDF</a>
                    <a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA/CelebA_Spoof.html">Dataset</a>
                    <a href="https://github.com/Davidzhangyuanhan/CelebA-Spoof">Code</a>
                    <a href="https://www.youtube.com/watch?v=A7XjSg5srvI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/sepstereo_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/Sep-Stereo">Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation</a>
                </strong>
                <br>
                <br>
                Hang Zhou*, Xudong Xu*, Dahua Lin, Xiaogang Wang, <b>Ziwei Liu</b>.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.09902">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/Sep-Stereo">Project Page</a>
                    <a href="https://github.com/SheldonTsui/SepStereo_ECCV2020">Code</a>
                    <a href="https://www.youtube.com/watch?v=njn7ctayUcI">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/placepedia_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hahehi.github.io/placepedia.html">Placepedia: Comprehensive Place Understanding with Multi-Faceted Annotations</a>
                </strong>
                <br>
                <br>
                Huaiyi Huang, Yuqi Zhang, Qingqiu Huang, Zhengkui Guo, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.03777">PDF</a>
                    <a href="https://hahehi.github.io/placepedia.html">Project Page</a>
                    <a href="https://github.com/hahehi/placepedia">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/selfsupdistillation_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2006.07114">Knowledge Distillation Meets Self-Supervision</a>
                </strong>
                <br>
                <br>
                Guodong Xu, <b>Ziwei Liu</b>, Xiaoxiao Li, Chen Change Loy.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2006.07114">PDF</a>
                    <a href="https://github.com/xuguodong03/SSKD">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unsup3dpose_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2007.07053">Unsupervised 3D Human Pose Representation with Viewpoint and Pose Disentanglement</a>
                </strong>
                <br>
                <br>
                Qiang Nie, <b>Ziwei Liu</b>, Yunhui Liu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.07053">PDF</a>
                    <a href="https://github.com/NIEQiang001/unsupervised-human-pose">Code</a>
                    <a href="https://www.youtube.com/watch?v=NVQqiTFrSqs">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <!-- <div class="publication">
            <img src="./homepage_files/pixelface_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/pixel-face/Pixel-Face">Pixel-Face: A Large-Scale, High-Resolution Benchmark for 3D Face Reconstruction</a>
                </strong>
                <br>
                <br>
                Yunxuan Zhang, Yu Rong, <b>Ziwei Liu</b>, Cheng Cheng.
                <br>
                <em>arXiv Preprint, 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2008.12444">PDF</a>
                    <a href="https://github.com/pixel-face/Pixel-Face">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br> -->
        <div class="publication">
            <img src="./homepage_files/ocda_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://liuziwei7.github.io/projects/CompoundDomain.html">Open Compound Domain Adaptation</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Zhongqi Miao*, Xingang Pan, Xiaohang Zhan, Dahua Lin, Stella X. Yu, Boqing Gong.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1909.03403">PDF</a>
                    <a href="https://liuziwei7.github.io/projects/CompoundDomain.html">Project Page</a>
                    <a href="https://github.com/zhmiao/OpenCompoundDomainAdaptation-OCDA">Code</a>
                    <a href="https://www.youtube.com/watch?v=YcmgCCRA1qc">Demo</a>
                    <a href="https://bair.berkeley.edu/blog/2020/06/14/ocda/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deocclusion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://xiaohangzhan.github.io/projects/deocclusion/">Self-Supervised Scene De-occlusion</a>
                </strong>
                <br>
                <br>
                Xiaohang Zhan, Xingang Pan, Bo Dai, <b>Ziwei Liu</b>, Dahua Lin, Chen Change Loy.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2004.02788">PDF</a>
                    <a href="https://xiaohangzhan.github.io/projects/deocclusion/">Project Page</a>
                    <a href="https://github.com/XiaohangZhan/deocclusion/">Code</a>
                    <a href="https://www.youtube.com/watch?v=xIHCyyaB5gU">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/onlineclustering_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/open-mmlab/OpenSelfSup">Online Deep Clustering for Unsupervised Representation Learning</a>
                </strong>
                <br>
                <br>
                Xiaohang Zhan*, Jiahao Xie*, <b>Ziwei Liu</b>, Yew-Soon Ong, Chen Change Loy.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2006.10645">PDF</a>
                    <a href="https://github.com/open-mmlab/OpenSelfSup">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/robustnas_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://www.mit.edu/~yuzhe/robnets.html">When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks</a>
                </strong>
                <br>
                <br>
                Minghao Guo*, Yuzhe Yang*, Rui Xu, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1911.10695">PDF</a>
                    <a href="http://www.mit.edu/~yuzhe/robnets.html">Project Page</a>
                    <a href="https://github.com/gmh14/RobNets">Code</a>
                    <a href="https://www.youtube.com/watch?v=Bj7MW4hCeeA">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/rotaterender_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2003.08124">Rotate-and-Render: Unsupervised Photorealistic Face Rotation without Paired Data</a>
                </strong>
                <br>
                <br>
                Hang Zhou, Jihao Liu, <b>Ziwei Liu</b>, Yu Liu, Xiaogang Wang.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2003.08124">PDF</a>
                    <a href="https://github.com/Hangz-nju-cuhk/Rotate-and-Render">Code</a>
                    <a href="https://www.youtube.com/watch?v=A12ckWqakTc">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/maskhq_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/switchablenorms/CelebAMask-HQ">MaskGAN: Towards Diverse and Interactive Facial Image Manipulation</a>
                </strong>
                <br>
                <br>
                Cheng-Han Lee, <b>Ziwei Liu</b>, Lingyun Wu, Ping Luo.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2020</em>
                <br>
                <br>
                <span class="links">
                	<a href="https://arxiv.org/abs/1907.11922">PDF</a>
                    <a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA/CelebAMask_HQ.html">Dataset</a>
                    <a href="https://github.com/switchablenorms/CelebAMask-HQ">Code</a>
                    <a href="https://www.youtube.com/watch?v=T1o38DFalWs">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/unsuplandmark_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2007.01053">Unsupervised Landmark Learning from Unpaired Data</a>
                </strong>
                <br>
                <br>
                Yinghao Xu, Ceyuan Yang, <b>Ziwei Liu</b>, Bo Dai, Bolei Zhou.
                <br>
                <em>arXiv Preprint, 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2007.01053">PDF</a>
                    <a href="https://github.com/justimyhxu/ULTRA">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fashioncollocation_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/2003.04888">Learning Diverse Fashion Collocation by Neural Graph Filtering</a>
                </strong>
                <br>
                <br>
                Xin Liu, Yongbin Sun, <b>Ziwei Liu</b>, Dahua Lin.
                <br>
                <em>IEEE Transactions on Multimedia (TMM), 2020</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2003.04888">PDF</a>
                    <a href="https://github.com/open-mmlab/mmfashion">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/pointgrow_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/PointGrow">PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention</a>
                </strong>
                <br>
                <br>
                Yongbin Sun, Yue Wang, <b>Ziwei Liu</b>, Joshua E. Siegel, Sanjay E. Sarma.
                <br>
                <em>Winter Conf. on Applications of Computer Vision (WACV), 2020 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1810.05591">PDF</a>
                    <a href="./projects/PointGrow">Project Page</a>
                    <a href="https://github.com/syb7573330/PointGrow">Code</a>
		    <a href="https://www.youtube.com/watch?v=sCKftYRtqBY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2019</h3>
        <div class="publication">
            <img src="./homepage_files/carafe_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/1905.02188">CARAFE: Content-Aware ReAssembly of FEatures</a>
                </strong>
                <br>
                <br>
                Jiaqi Wang, Kai Chen, Rui Xu, <b>Ziwei Liu</b>, Chen Change Loy, Dahua Lin.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2019 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1905.02188">PDF</a>
                    <a href="https://github.com/myownskyW7/CARAFE">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/3dhuman_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://penincillin.github.io/dct_iccv2019">Delving Deep into Hybrid Annotations for 3D Human Recovery in the Wild</a>
                </strong>
                <br>
                <br>
                Yu Rong, <b>Ziwei Liu</b>, Cheng Li, Kaidi Cao, Chen Change Loy.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1908.06442">PDF</a>
                    <a href="https://penincillin.github.io/dct_iccv2019">Project Page</a>
                    <a href="https://github.com/penincillin/DCT_ICCV-2019">Code</a>
                    <a href="https://www.youtube.com/watch?v=8TULGUsb4ZE">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/audioinpaint_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://hangz-nju-cuhk.github.io/projects/AudioInpainting">Vision-Infused Deep Audio Inpainting</a>
                </strong>
                <br>
                <br>
                Hang Zhou, <b>Ziwei Liu</b>, Xudong Xu, Ping Luo, Xiaogang Wang.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1910.10997">PDF</a>
                    <a href="https://hangz-nju-cuhk.github.io/projects/AudioInpainting">Project Page</a>
                    <a href="https://github.com/Hangz-nju-cuhk/Vision-Infused-Audio-Inpainter-VIAI">Code</a>
                    <a href="https://www.youtube.com/watch?v=2C8s_YuRRxk">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/facereenact_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://wywu.github.io/projects/ReenactGAN/OneShotReenact.html">One-shot Face Reenactment</a>
                </strong>
                <br>
                <br>
                Yunxuan Zhang, Siwei Zhang, Yue He, Cheng Li, Chen Change Loy, <b>Ziwei Liu</b>.
                <br>
                <em>British Machine Vision Conference (BMVC), 2019 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1908.03251">PDF</a>
                    <a href="https://wywu.github.io/projects/ReenactGAN/OneShotReenact.html">Project Page</a>
                    <a href="https://github.com/bj80heyue/One_Shot_Face_Reenactment">Code</a>
                    <a href="https://www.youtube.com/watch?v=FE-D6wh11_A">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/longtail_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://liuziwei7.github.io/projects/LongTail.html">Large-scale Long-Tailed Recognition in an Open World</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Zhongqi Miao*, Xiaohang Zhan, Jiayun Wang, Boqing Gong, Stella X. Yu.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2019 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <em><font color="red" size="2">(HKSTP Best Paper Award)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1904.05160">PDF</a>
                    <a href="https://liuziwei7.github.io/projects/LongTail.html">Project Page</a>
                    <a href="https://github.com/zhmiao/OpenLongTailRecognition-OLTR">Code</a>
                    <a href="https://www.youtube.com/watch?v=A45wrs1g8VA">Demo</a>
                    <a href="https://bair.berkeley.edu/blog/2019/05/13/oltr/">Press</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/motionprop_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CMP/">Self-Supervised Learning via Conditional Motion Propagation</a>
                </strong>
                <br>
                <br>
                Xiaohang Zhan, Xingang Pan, <b>Ziwei Liu</b>, Dahua Lin, Chen Change Loy.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1903.11412">PDF</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CMP/">Project Page</a>
                    <a href="https://github.com/XiaohangZhan/conditional-motion-propagation/">Code</a>
                    <a href="https://www.youtube.com/watch?v=6R_oJCq5qMw">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/taskcascade_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/HybridTaskCascade/">Hybrid Task Cascade for Instance Segmentation</a>
                </strong>
                <br>
                <br>
                Kai Chen, Jiangmiao Pang, Jiaqi Wang, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, <b>Ziwei Liu</b>, Jianping Shi, Wanli Ouyang, Chen Change Loy, Dahua Lin.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2019 <font color="#e86e14">(Winning Entry of COCO 2018 Challenge)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1901.07518">PDF</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/HybridTaskCascade/">Project Page</a>
                    <a href="https://github.com/open-mmlab/mmdetection">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/mmdet_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://github.com/open-mmlab/mmdetection">MMDetection: Open MMLab Detection Toolbox and Benchmark</a>
                </strong>
                <br>
                <br>
                Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, <b>Ziwei Liu</b>, Jiarui Xu, Zheng Zhang, Dazhi Cheng, Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu, Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy, Dahua Lin.
                <br>
                <em>arXiv Preprint, 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1906.07155">PDF</a>
                    <a href="https://github.com/open-mmlab/mmdetection">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fashiontextures_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/1911.07472">Learning to Synthesize Fashion Textures</a>
                </strong>
                <br>
                <br>
                Wu Shi, Tak-Wai Hui, <b>Ziwei Liu</b>, Dahua Lin, Chen Change Loy.
                <br>
                <em>arXiv Preprint, 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1911.07472">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/cameratrap_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.nature.com/articles/s41598-019-44565-w">Insights and Approaches using Deep Learning to Classify Wildlife</a>
                </strong>
                <br>
                <br>
                Zhongqi Miao, Kaitlyn M Gaynor, Jiayun Wang, <b>Ziwei Liu</b>, Oliver Muellerklein, Mohammad S Norouzzadeh, Alex McInturff, Rauri C K Bowie, Ran Nathon, Stella X. Yu, Wayne M. Getz.
                <br>
                <br>
                <em>Nature - Scientific Reports, 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.nature.com/articles/s41598-019-44565-w">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/talkingface_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/TalkingFace">Talking Face Generation by Adversarially Disentangled Audio-Visual Representation</a>
                </strong>
                <br>
                <br>
                Hang Zhou, Yu Liu, <b>Ziwei Liu</b>, Ping Luo, Xiaogang Wang.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2019 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1807.07860">PDF</a>
                    <a href="./projects/TalkingFace">Project Page</a>
                    <a href="https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS">Code</a>
                    <a href="https://www.youtube.com/watch?v=-J2zANwdjcQ">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/attributetransfer_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/attribute-transfer/">Instance-level Facial Attributes Transfer with Geometry-Aware Flow</a>
                </strong>
                <br>
                <br>
                Weidong Yin, <b>Ziwei Liu</b>, Chen Change Loy.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2019 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1811.12670">PDF</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/attribute-transfer/">Project Page</a>
                    <a href="https://github.com/wdyin/GeoGAN">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dpatch_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://arxiv.org/abs/1806.02299">DPatch: An Adversarial Patch Attack on Object Detectors</a>
                </strong>
                <br>
                <br>
                Xin Liu, Huanrui Yang, <b>Ziwei Liu</b>, Linghao Song, Hai Li, Yiran Chen.
                <br>
                <em>AAAI Workshop on Artificial Intelligence Safety (SafeAI), 2019</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1806.02299">PDF</a>
                    <a href="https://github.com/veralauee/DPatch">Code</a>
                    <a href="https://www.youtube.com/watch?v=-aPbU9q1gFU">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/dynamicgcnn_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/DGCNN">Dynamic Graph CNN for Learning on Point Clouds</a>
                </strong>
                <br>
                <br>
                Yue Wang, Yongbin Sun, <b>Ziwei Liu</b>, Sanjay Sarma, Michael Bronstein, Justin Solomon.
                <br>
                <em>ACM Transactions on Graphics (TOG), 2019</em>
                <br>
                <em><font color="red" size="2">(ICBS 2023 Frontiers of Science Award)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1801.07829">PDF</a>
                    <a href="./projects/DGCNN">Project Page</a>
                    <a href="https://github.com/WangYueFt/dgcnn">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2018</h3>
        <div class="publication">
            <img src="./homepage_files/wildlife_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://www.biorxiv.org/content/early/2018/10/22/450189">A Comparison of Visual Features used by Humans and Machines to Classify Wildlife</a>
                </strong>
                <br>
                <br>
                Zhongqi Miao, Kaitlyn M Gaynor, Jiayun Wang, <b>Ziwei Liu</b>, Oliver Muellerklein, Mohammad S Norouzzadeh, Alex McInturff, Rauri C K Bowie, Ran Nathon, Stella X. Yu, Wayne M. Getz.
                <br>
                <em>BiorXiv Preprint, 2018</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://www.biorxiv.org/content/early/2018/10/22/450189">PDF</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/im2avatar_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/Im2Avatar">Im2Avatar: Colorful 3D Reconstruction from a Single Image</a>
                </strong>
                <br>
                <br>
                Yongbin Sun, <b>Ziwei Liu</b>, Yue Wang, Sanjay E. Sarma.
                <br>
                <em>arXiv Preprint, 2018</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1804.06375">PDF</a>
                    <a href="./projects/Im2Avatar">Project Page</a>
                    <a href="https://www.dropbox.com/s/imgiu8xump2zlvm/human_im2avatar.tar.gz">Dataset</a>
                    <a href="https://github.com/syb7573330/im2avatar">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/consensusprop_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CDP/">Consensus-Driven Propagation in Massive Unlabeled Data for Face Recognition</a>
                </strong>
                <br>
                <br>
                Xiaohang Zhan, <b>Ziwei Liu</b>, Junjie Yan, Dahua Lin, Chen Change Loy.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2018</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1809.01407">PDF</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CDP/">Project Page</a>
                    <a href="https://github.com/XiaohangZhan/cdp/">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/affinityseg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://jyhjinghwang.github.io/projects/aaf.html">Adaptive Affinity Field for Semantic Segmentation</a>
                </strong>
                <br>
                <br>
                Tsung-Wei Ke*, Jyh-Jing Hwang*, <b>Ziwei Liu</b>, Stella X. Yu.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2018</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1803.10335">PDF</a>
                    <a href="https://jyhjinghwang.github.io/projects/aaf.html">Project Page</a>
                    <a href="https://github.com/twke18/Adaptive_Affinity_Fields">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/selfsupseg_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/M&M/">Mix-and-Match Tuning for Self-Supervised Semantic Segmentation</a>
                </strong>
                <br>
                <br>
                Xiaohang Zhan, <b>Ziwei Liu</b>, Ping Luo, Xiaoou Tang, Chen Change Loy.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2018 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1712.00661">PDF</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/M&M/">Project Page</a>
                    <a href="https://github.com/XiaohangZhan/mix-and-match">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2017</h3>
        <div class="publication">
            <img src="./homepage_files/voxelflow_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/VoxelFlow">Video Frame Synthesis using Deep Voxel Flow</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu</b>, Raymond A. Yeh, Xiaoou Tang, Yiming Liu, Aseem Agarwala.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2017 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1702.02463">PDF</a>
                    <a href="./projects/VoxelFlow">Project Page</a>
                    <a href="https://github.com/liuziwei7/voxel-flow">Code</a>
                    <a href="https://store.google.com/us/product/google_clips?hl=en-US">Product Transfer</a>
                </span>
            </p>
        </div>
        <br>
		<br>
		<div class="publication">
            <img src="./homepage_files/unconstrainedlandmarks_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/UnconstrainedLandmarks.html">Unconstrained Fashion Landmark Detection via Hierarchical Recurrent Transformer Networks</a>
                </strong>
                <br>
                <br>
                Sijie Yan, <b>Ziwei Liu</b>, Ping Luo, Shi Qiu, Xiaogang Wang, Xiaoou Tang.
                <br>
                <em>ACM Multimedia (ACM MM), 2017 <font color="#e86e14">(Full Research Paper)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1708.02044">PDF</a>
                    <a href="./projects/UnconstrainedLandmarks.html">Project Page</a>
                    <a href="https://github.com/yysijie/DLAN/">Code</a>
                    <a href="https://www.youtube.com/watch?v=uFpurN6dDiY">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
		<div class="publication">
            <img src="./homepage_files/vsreid_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/VSReID.html">Video Object Segmentation with Re-identification</a>
                </strong>
                <br>
                <br>
                Xiaoxiao Li, Yuankai Qi, Zhe Wang, Kai Chen, <b>Ziwei Liu</b>, Jianping Shi, Ping Luo, Xiaoou Tang, Chen Change Loy.
                <br>
                <em>CVPR Workshop on DAVIS Video Seg. Challenge, 2017 <font color="#e86e14">(Winning Entry)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1708.00197">PDF</a>
                    <a href="./projects/VSReID.html">Project Page</a>
                    <a href="https://github.com/lxx1991/VS-ReID">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/layercascade_logo.jpg" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/LayerCascade.html">Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade</a>
                </strong>
                <br>
                <br>
                Xiaoxiao Li, <b>Ziwei Liu</b>, Ping Luo, Chen Change Loy, Xiaoou Tang.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2017 <font color="#e86e14">(Spotlight)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1704.01344">PDF</a>
                    <a href="./projects/LayerCascade.html">Project Page</a>
                    <a href="https://github.com/liuziwei7/region-conv">Code</a>
                    <a href="https://www.youtube.com/watch?v=oMhyQsT8jMA">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deepparsingnetwork_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/DPN.html">Deep Learning Markov Random Field for Semantic Segmentation</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Xiaoxiao Li*, Ping Luo, Chen Change Loy, Xiaoou Tang.
                <br>
                <em>Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017</em>
                <br>
                <br>
                <span class="links">
                    <a href="http://arxiv.org/abs/1606.07230">PDF</a>
                    <a href="./projects/DPN.html">Project Page</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/calibration_logo.jpg" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./papers/robotcalibration.pdf">Vision-Based Calibration of Dual RCM-Based Robot Arms in Human-Robot Collaborative Minimally Invasive Surgery</a>
                </strong>
                <br>
                <br>
                Zerui Wang, <b>Ziwei Liu</b>, Qianli Ma, Alexis Cheng, Yun-hui Liu, Sungmin Kim, Anton Deguet, Austin Reiter, Peter Kazanzides, Russell H. Taylor.
                <br>
                <em>International Conference on Intelligent Robots and Systems (IROS), 2017</em>
                <em>IEEE Robotics and Automation Letters (RA-L), 2017</em>
                <br>
                <br>
                <span class="links">
                    <a href="./papers/robotcalibration.pdf">PDF</a>
                    <a href="https://github.com/liuziwei7/centerline-detection">Code</a>
                </span>
            </p>
        </div>
        <br>
		<br>
		<br>
		<br>
        <br>
        </div>

        <div class="container">
		<h3>2016</h3>
		<div class="publication">
            <img src="./homepage_files/expressionediting_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="https://raymondyeh07.github.io/projects/face_edit/index.html">Semantic Facial Expression Editing using Autoencoded Flow</a>
                </strong>
                <br>
                <br>
                Raymond A. Yeh, <b>Ziwei Liu</b>, Dan B Goldman, Aseem Agarwala.
                <br>
                <em>arXiv Preprint, 2016</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1611.09961">PDF</a>
                    <a href="https://raymondyeh07.github.io/projects/face_edit/index.html">Project Page</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/fashionlandmarks_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/FashionLandmarks.html">Fashion Landmark Detection in the Wild</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Sijie Yan*, Ping Luo, Xiaogang Wang, Xiaoou Tang.
                <br>
                <em>European Conference on Computer Vision (ECCV), 2016</em>
                <br>
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/1608.03049">PDF</a>
                    <a href="./projects/FashionLandmarks.html">Project Page</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/LandmarkDetection.html">Dataset</a>
                    <a href="https://github.com/liuziwei7/fashion-landmarks">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/deepfashion_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/DeepFashion.html">DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu</b>, Ping Luo, Shi Qiu, Xiaogang Wang, Xiaoou Tang.
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR), 2016</em>
                <br>
                <br>
                <span class="links">
                    <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf">PDF</a>
                    <a href="./projects/DeepFashion.html">Project Page</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html">Dataset</a>
                    <a href="https://github.com/open-mmlab/mmfashion">Code</a>
                    <a href="http://fashion.sensetime.com/">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <br>
		<div class="publication">
            <img src="./homepage_files/modelcompression_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/MobileID.html">Face Model Compression by Distilling Knowledge from Neurons</a>
                </strong>
                <br>
                <br>
                Ping Luo*, Zhenyao Zhu*, <b>Ziwei Liu</b>, Xiaogang Wang, Xiaoou Tang.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI), 2016 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="http://personal.ie.cuhk.edu.hk/~pluo/pdf/aaai16-face-model-compression.pdf">PDF</a>
                    <a href="./projects/MobileID.html">Project Page</a>
                    <a href="https://github.com/liuziwei7/mobile-id">Code</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        </div>

        <div class="container">
        <h3>2015 and before</h3>
        <div class="publication">
            <img src="./homepage_files/semanticsegmentation_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/DPN.html">Semantic Image Segmentation via Deep Parsing Network</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu*</b>, Xiaoxiao Li*, Ping Luo, Chen Change Loy, Xiaoou Tang.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2015 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="http://arxiv.org/abs/1509.02634">PDF</a>
                    <a href="./projects/DPN.html">Project Page</a>
                    <a href="https://www.youtube.com/watch?v=kfP8zeNOzHs">Demo</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/faceattributes_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/FaceAttributes.html">Deep Learning Face Attributes in the Wild</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu</b>, Ping Luo, Xiaogang Wang, Xiaoou Tang.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2015</em>
                <br>
                <br>
                <span class="links">
                    <a href="http://arxiv.org/abs/1411.7766">PDF</a>
                    <a href="./projects/FaceAttributes.html">Project Page</a>
                    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Dataset</a>
                </span>
            </p>
        </div>
        <br>
        <br>
        <div class="publication">
            <img src="./homepage_files/burstdenoising_logo.png" class="publogo" width="200 px">
            <p> 
                <strong>
                    <a href="./projects/BurstDenoising.html">Fast Burst Images Denoising</a>
                </strong>
                <br>
                <br>
                <b>Ziwei Liu</b>, Lu Yuan, Xiaoou Tang, Matt Uyttendaele, Jian Sun.
                <br>
                <em>ACM Transactions on Graphics (SIGGRAPH Asia), 2014 <font color="#e86e14">(Oral)</font> </em>
                <br>
                <br>
                <span class="links">
                    <a href="./papers/burstdenoising.pdf">PDF</a>
                    <a href="./projects/BurstDenoising.html">Project Page</a>
                    <a href="https://www.dropbox.com/sh/uoij1g8av5thvkg/AAC0fhWvvA50KRxrD5aMUCkHa?dl=0">Dataset</a>
                    <a href="https://itunes.apple.com/app/id1064676206?mt=8">Product Transfer</a>
                </span>
            </p>
        </div>
        <br>
        <br>
    </div>

</body></html>



<!-- <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->

<!-- Meta tags for search engines to crawl -->
<!-- <meta name="robots" content="index,follow">
<meta name="keywords" content="Ziwei Liu; 刘子纬; Computer Vision; Deep Learning; Computer Graphics; Multimedia Lab; MMLAB; The Chinese University of Hong Kong; CUHK; UC Berkeley; ICSI; Nanyang Technological University; NTU">
<link rel="author" href="https://liuziwei7.github.io/">

    <title>Ziwei Liu - Publications</title>
    <style>

@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 30px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>
    
    <div class="title">
        <div id="sidebar"><img src="./homepage_files/me.jpg" vspace="50 px" width="300 px" id="me" itemprop="photo"></div>
        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Ziwei Liu <font size="5">刘子纬</font> </span>
            </h1>

            <br>

            <p style="line-height:23px;">
                Assistant Professor
                <br>
                <br>
                School of Computer Science and Engineering
                <br>
                <br>
                Nanyang Technological University
                <br>
                <br>
                Email: ziwei.liu at ntu.edu.sg
                <br>
            </p>

            <br>

            <p class="external">
                <a href="https://scholar.google.com/citations?user=lc45xlcAAAAJ" class="first">Google Scholar</a>
                <a href="https://github.com/liuziwei7">GitHub</a>
            </p>
        </div>
    </div>

    <div class="container">
        <h2>Short Bio</h2>
        <p>
            Prof. Ziwei Liu is a <a href="https://www.ntu.edu.sg/tracs/nap/Pages/home.aspx">Nanyang Assistant Professor</a> at <a href="http://scse.ntu.edu.sg/Pages/Home.aspx">School of Computer Science and Engineering (SCSE)</a> in <a href="https://www.ntu.edu.sg/Pages/home.aspx">Nanyang Technological University (NTU)</a>.
            Previously, he was a research fellow (2018-2020) in <a href="http://www.cuhk.edu.hk/english/index.html">CUHK</a> (with Prof. <a href="http://dahua.me/">Dahua Lin</a>) and a post-doc researcher (2017-2018) in <a href="http://www.berkeley.edu/">UC Berkeley</a> (with Prof. <a href="http://www1.icsi.berkeley.edu/~stellayu/">Stella X. Yu</a>). His research interests include computer vision, machine learning and computer graphics. 
            <br>
            <br>
            Ziwei received his Ph.D. (2013-2017) from <a href="http://www.cuhk.edu.hk/english/index.html">CUHK</a> / <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Lab</a>, advised by Prof. <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a> and Prof. <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a>. He is fortunate to have internships at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a> and <a href="https://research.google.com/">Google Research</a>.
        <br>
            <br>
        His works include <a href="https://liuziwei7.github.io/projects/BurstDenoising.html">Burst Denoising</a>, <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a>, <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html">DeepFashion</a>, <a href="https://liuziwei7.github.io/projects/FashionLandmarks.html">Fashion Landmarks</a>, <a href="https://liuziwei7.github.io/projects/DPN">DeepMRF</a>, <a href="https://liuziwei7.github.io/projects/VoxelFlow">Voxel Flow</a>, <a href="https://liuziwei7.github.io/projects/LongTail">Long-Tailed Recognition</a>, and <a href="https://liuziwei7.github.io/projects/CompoundDomain">Compound Domain Adaptation</a>.
        </p>
    </div>

    <div class="container">
        <h2>News</h2>
        <p>
        [2021-03] Ten papers accepted to <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a> (3 orals and 7 posters).
        <br>
        <br>
        [2021-01] Two papers accepted to <a href="https://iclr.cc/">ICLR 2021</a> (1 oral and 1 spotlight).
        <br>
        <br>
        [2020-11] Senior Program Committee for <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a> and Area Chair for <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>.
        <br>
        <br>
        [2020-10] Invited talk (<a href="./papers/openworldhuman_slides.pdf">slides</a>) at ACM MM 2020 workshop on <a href="https://hcma2020.github.io/">Human-Centric Multimedia Analysis</a>.
        <br>
        <br>
        [2020-09] Associate Editor for <a href="https://digital-library.theiet.org/content/journals/iet-cvi">IET Computer Vision</a>.
        <br>
        <br>
        [2020-08] We are hosting <a href="https://competitions.codalab.org/competitions/25228">DeeperForensics</a> and <a href="https://competitions.codalab.org/competitions/26210">CelebA-Spoof</a> Challenge.
        <br>
        <br>
        [2020-06] We are organizing ECCV 2020 <a href="https://sense-human.github.io/">SenseHuman Workshop</a>.
        <br>
        <br>
        [2020-06] We have released <a href="https://github.com/open-mmlab/OpenSelfSup">OpenSelfSup</a> Toolbox v0.1.
        <br>
        <br>
        [2020-06] We won the first place in <a href="https://vuhcs.github.io/">Video Virtual Try-on Challenge</a>.
        <br>
        <br>
        [2020-03] Guest Editor for <a href="https://www.frontiersin.org/research-topics/13353/learning-sensing-and-control-for-autonomous-manipulation-of-deformable-objects">Frontiers in Robotics and AI</a>.
        <br>
        <br>
        [2019-11] We have released <a href="https://github.com/open-mmlab/mmfashion">MMFashion</a> Toolbox v0.1.
        <br>
        <br>
        [2019-10] Invited talk (<a href="./papers/diversehuman_slides.pdf">slides</a>) at ICCV 2019 workshop on <a href="https://sites.google.com/view/cvcreative">Computer Vision for Fashion, Art and Design</a>.
        <br>
        <br>
        [2019-10] Invited talk (<a href="./papers/odc_slides.pdf">slides</a>) at ICCV 2019 workshop on <a href="https://sites.google.com/view/extremevision">Extreme Vision Modeling</a>.
        <br>
        <br>
        [2019-10] We won all four tracks in <a href="https://sites.google.com/view/fb-ssl-challenge-iccv19/home#h.p_9Fr5HPghQVP7">Facebook AI Self-Supervision Challenge</a>.
        <br>
        <br>
        [2019-10] We are organizing ICCV 2019 <a href="https://sense-human.github.io/index_2019.html">SenseHuman Workshop</a>.
        </p>
    </div> -->



<!--     <div class="container">
    	<h2>Talks</h2>
    	<div>
    		<p>
            <br>
            2020 @ ACM MM: <em><a href="./papers/openworldhuman_slides.pdf">Sensing, Understanding and Synthesizing Humans in an Open World</a></em>
            <br>
            <br>
            2019 @ ICCV: <em><a href="./papers/diversehuman_slides.pdf">Learning Diverse Human Representation in the Wild</a></em>
            <br>
            <br>
            2019 @ VALSE: <em><a href="./papers/glimpseofdetectron_slides.pdf">The Glimpse of Detectron: Dynamic Forwarding and Routing in Modern Detectors</a></em>
            <br>
            <br>
            2018 @ Berkeley: <em><a href="./papers/videoparsing_slides.pdf">Learning Video Parsing, Tracking and Synthesis in the Wild</a></em>
            <br>
            <br>
    		2017 @ VALSE: <em><a href="./papers/humancentric_slides.pdf">Deep Learning Human-centric Representation in the Wild</a></em>
    		<br>
    		<br>
            2016 @ Google: <em><a href="./papers/deepfashion_slides.pdf">Deep Fashion Understanding</a></em>
    		<br>
    		<br>
    		2015 @ CUHK: <em><a href="./papers/visualstructures_slides.pdf">Formulating Structure for Vision Problems</a></em>
            <br>
            <br>
            2014 @ SIGGRAPH Asia: <em><a href="./papers/burstdenoising_slides.pdf">Fast Burst Images Denoising</a></em>
            <br>
            <br>
            2013 @ HUST: <em><a href="./papers/microscopicimageseg_slides.pdf">Pathological Microscopic Image Segmentation (in Chinese)</a></em>
   			</p>
    	</div>
    </div>

    <div class="container">
    	<h2>Teaching</h2>
    	<div>
    		<p>
    		<br>
            FYP 16-17: <em><a href="./papers/pose2landmarks_poster.pdf">Fashion Landmark Detection</a></em>
            <br>
    		<br>
            FYP 15-16: <em><a href="./papers/fashionattributes_poster.pdf">Fashion Attributes Prediction</a> and <a href="./papers/fashionstyle_poster.pdf">Style Transfer</a></em>
            <br>
            <br>
    		FYP 14-15: <em>Face Attributes Recognition on Web Images</em>
    		<br>
    		<br>
    		IERG 2600: <em>Technology, Society and Engineering Practice</em>
    		<br>
    		<br>
    		IERG 3080: <em>Information & Software Engineering Practice</em>
   			</p>
    	</div>
    </div>

    <div class="container">
    	<h2>Misc</h2>
    	<div>
    		<p>
    		<br>
    		<span class="links">
                <a href="https://blindsights.blogspot.com/">Blog</a>
                &nbsp;&nbsp;&nbsp;
                <a href="https://goo.gl/photos/CE8chhuJwTAcZqtL7">Doodles</a>
                &nbsp;&nbsp;&nbsp;
                <a href="https://www.youtube.com/playlist?list=PLua4XbbBXzFciVTrYVhZB3Kt7-ZERzzXp">Microcinema</a>
            </span>
   			</p>
    	</div>
    </div> -->
